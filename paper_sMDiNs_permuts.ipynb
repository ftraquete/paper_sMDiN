{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Mass-Difference Networks in Metabolomics Data Analysis\n",
    "\n",
    "Notebook to support the study on the application of **Sample M**ass-**Di**fference **N**etworks as a highly specific competing form of pre-processing procedure for high-resolution metabolomics data.\n",
    "\n",
    "Mass-Difference Networks are focused into making networks from a list of masses. Each _m/z_ will represent a node. Nodes will be connected if the difference in their masses can be associated to a simple chemical reaction (enzymatic or non-enzymatic) that led to a change in the elemental composition of its metabolite.\n",
    "\n",
    "The set of mass differences used to build said networks are called a set of MDBs - Mass-Difference-based Building block.\n",
    "\n",
    "This is notebook `paper_sMDiNs_permuts.ipynb`\n",
    "\n",
    "\n",
    "## Organization of the Notebook\n",
    "\n",
    "- Loading up pre-processed and pre-treated datasets databases with intensity-based pre-treated data and data from sMDiNs analyses.\n",
    "- **Permutation tests generation and figure representation**\n",
    "\n",
    "Permutation tests are slow to generate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Needed Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.testing import assert_frame_equal\n",
    "from numpy.random import default_rng\n",
    "\n",
    "import scipy.spatial.distance as dist\n",
    "import scipy.cluster.hierarchy as hier\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import ticker\n",
    "\n",
    "import sklearn.ensemble as skensemble\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "\n",
    "# Metabolinks package\n",
    "import metabolinks as mtl\n",
    "import metabolinks.transformations as transf\n",
    "\n",
    "# Python files in the repository\n",
    "import multianalysis as ma\n",
    "\n",
    "# json for persistence\n",
    "\n",
    "import json\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of dataset records\n",
    "\n",
    "`datasets` is the global dict that holds all data sets. It is a **dict of dict's**.\n",
    "\n",
    "Each data set is **represented as a dict**.\n",
    "\n",
    "Each record has the following fields (keys):\n",
    "\n",
    "- `name`: the table/figure name of the data set\n",
    "- `source`: the biological source for each dataset\n",
    "- `mode`: the aquisition mode\n",
    "- `alignment`: the alignment used to generate the data matrix\n",
    "- `data`: the data matrix\n",
    "- `target`: the sample labels, possibly already integer encoded\n",
    "- `MDiN`: Mass-Difference Network - Not present here, only on sMDiNsAnalysis notebook\n",
    "- `<treatment name>`: transformed data matrix / network. These treatment names can be\n",
    "    - `Ionly`: missing value imputed data by 1/5 of the minimum value in each sample in the dataset, only\n",
    "    - `NGP`: normalized, glog transformed and Pareto scaled\n",
    "    - `Ionly_RF`: missing value imputed data by random forests, only\n",
    "    - `NGP_RF`: normalized, glog transformed and Pareto scaled\n",
    "    - `IDT`: `NGP_RF` or `NGP` - Intensity-based Data pre-Treatment chosen as comparison based on which of the two performed better for each dataset and each statistical method\n",
    "    - `sMDiN`: Sample Mass-Difference Networks - Not present here, only on sMDiNsAnalysis notebook\n",
    "       \n",
    "- `<sMDiN analysis name>`: data matrix from nework analysis of MDiNs - Not in this notebook\n",
    "    - `Degree`: degree analysis of each sMDiN\n",
    "    - `Betweenness`: betweenness centrality analysis of each sMDiN\n",
    "    - `Closeness`: closeness centrality of analysis of each sMDiN\n",
    "    - `MDBI`: analysis on the impact of each MDB (Mass-Difference based building-block) on building each sMDiN\n",
    "    - `GCD11`: Graphlet Correlation Distance of 11 different orbits (maximum of 4-node graphlets) between each sMDiN.\n",
    "    - `WMDBI`: an alternative calculation of MDBI using the results from the degree analysis.\n",
    "\n",
    "- `iter_fold_splits`: contains nested dicts that identify and contain each transformed training and testing groups data matrices with their respective iteration, training/test, fold number and one of the previously mentioned data pre-treatments\n",
    "- `train`: specific to the HD dataset; contains a set of the different pre-treatments and sMDin analysis mentioned and a target based on the training set defined for HD\n",
    "- `test`: specific to the HD dataset; contains a set of the different pre-treatments and sMDin analysis mentioned and a target based on the external test set defined for HD\n",
    "\n",
    "\n",
    "The keys of `datasets` may be shared with dicts holding records resulting from comparison analysis.\n",
    "\n",
    "Here are the keys (and respective names) of datasets used in this study:\n",
    "\n",
    "- GD_global2 (GDg2)\n",
    "- GD_class2 (GDc2)\n",
    "- YD (YD)\n",
    "- vitis_types (GD types)\n",
    "- HD (HD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Pre-Treatment\n",
    "\n",
    "For information on the **commonly used intensity based data pre-treatments** and about the **benchmark datasets**, see notebook `paper_sMDiNs_database_prep.ipynb`.\n",
    "\n",
    "For information on the **building** and the different **network analysis methods** used for the **Sample MDiNs** and information about the Mass-Difference-based Building blocks (**MDBs**), see notebook `paper_sMDiNs_sMDiNsAnalysis.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading datasets database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where the datasets are\n",
    "path = Path.cwd() / \"store_files\" / 'processed_data.json'\n",
    "storepath = Path.cwd() / \"store_files\" / 'processed_data.h5'\n",
    "with pd.HDFStore(storepath) as store:\n",
    "    \n",
    "    # Read into a dictionary not DataFrame data\n",
    "    with open(path, encoding='utf8') as read_file:\n",
    "        datasets = json.load(read_file)\n",
    "    \n",
    "    # Add DataFrame data to dict\n",
    "    for dskey, dataset in datasets.items():\n",
    "        dataset['iter_fold_splits'] = {}\n",
    "        if dskey == 'HD':\n",
    "            dataset['train'] = {}\n",
    "            dataset['test'] = {}\n",
    "        for key in dataset:\n",
    "            # Created right before\n",
    "            if 'iter_fold_splits' == key:\n",
    "                continue\n",
    "            value = dataset[key]\n",
    "            if isinstance(value, str) and value.startswith(\"INSTORE\"):\n",
    "                storekey = value.split(\"_\", 1)[1]\n",
    "                #print(storekey)\n",
    "                # Load the data from 'iter_fold_splits' carefully restoring the nested dictionaries\n",
    "                if len(storekey.split(\"AA_\")) > 1: # This separation was made to identify the 'iter_fold_splits' data\n",
    "                    dictkeys = (storekey.split(\"AA_\")[1]).split('_',3)\n",
    "                    # Create nested dicts\n",
    "                    if int(dictkeys[0]) not in dataset['iter_fold_splits'].keys():\n",
    "                        dataset['iter_fold_splits'][int(dictkeys[0])] = {}\n",
    "                    if dictkeys[1] not in dataset['iter_fold_splits'][int(dictkeys[0])].keys():\n",
    "                        dataset['iter_fold_splits'][int(dictkeys[0])][dictkeys[1]] = {}\n",
    "                    if int(dictkeys[2]) not in dataset['iter_fold_splits'][int(dictkeys[0])][dictkeys[1]].keys():\n",
    "                        dataset['iter_fold_splits'][int(dictkeys[0])][dictkeys[1]][int(dictkeys[2])] = {}\n",
    "                    dataset['iter_fold_splits'][int(dictkeys[0])][dictkeys[1]][int(dictkeys[2])][dictkeys[3]] = store[storekey]\n",
    "                \n",
    "                # Load the data from 'train' and 'test' from HD dataset keys carefully restoring the nested dictionaries\n",
    "                elif len(storekey.split(\"TTS_\")) > 1:\n",
    "                    dictkeys = ((storekey.split(\"TTS_\")[0]).split('_')[-1], storekey.split(\"TTS_\")[1])#.split('_',2)\n",
    "                    dataset[dictkeys[0]][dictkeys[1]] = store[storekey]\n",
    "                # Normal DataFrames\n",
    "                else:\n",
    "                    dataset[key] = store[storekey]\n",
    "\n",
    "            # convert colors to tuples, since they are read as lists from json file\n",
    "            elif key == 'label_colors':\n",
    "                dataset[key] = {lbl: tuple(c) for lbl, c in value.items()}\n",
    "            elif key == 'sample_colors':\n",
    "                dataset[key] = [tuple(c) for c in value]\n",
    "            elif key.endswith('target') and key.startswith(dskey):\n",
    "                if len(key.split(\"AA_\")) > 1: \n",
    "                    dictkeys = ((key.split(\"_\", 1)[1]).split(\"AA_\")[1]).split('_',3)\n",
    "                    dataset['iter_fold_splits'][int(dictkeys[0])][dictkeys[1]][int(dictkeys[2])][dictkeys[3]] = value\n",
    "                else:\n",
    "                    dictkeys = ((key.split(\"TTS_\")[0]).split('_')[-1], key.split(\"TTS_\")[1])#.split('_',2)\n",
    "                    dataset[dictkeys[0]][dictkeys[1]] = value\n",
    "\n",
    "# Remove extra keys\n",
    "for name, ds in datasets.items():\n",
    "    keys_to_remove = [keys for keys in ds.keys() if keys.startswith(name)]\n",
    "    for key in keys_to_remove:\n",
    "        ds.pop(key)\n",
    "#datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a placeholder for the Intensity-based Data pre-Treatment (IDT)\n",
    "# Chosen for each dataset and each method based on which between NGP and NGP_RF generated the best results\n",
    "for name, ds in datasets.items():\n",
    "    ds['IDT'] = ds['NGP_RF']  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Possibly Useful Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemical Formula transformations (MDBs chosen)\n",
    "MDB = ['H2','CH2','CO2','O','CHOH','NCH','O(N-H-)','S','CONH','PO3H','NH3(O-)','SO3','CO', 'C2H2O', 'H2O']\n",
    "MDB_YD = ['H2','CH2','CO2','O','CHOH','NCH','O(N-H-)','S','CONH','PO3H','NH3(O-)','SO3','CO', 'C2H2O', 'H2O', \n",
    "          'C2H2O2', 'C3H4O2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colors for plots to ensure consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11 variety grapevine data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize label colors for 11 grapevine varieties\n",
    "\n",
    "colours = sns.color_palette('Blues', 3)\n",
    "colours.extend(sns.color_palette('Greens', 3))\n",
    "#colours = sns.cubehelix_palette(n_colors=6, start=2, rot=0, dark=0.2, light=.9, reverse=True)\n",
    "colours.extend(sns.color_palette('flare', 5))\n",
    "\n",
    "ordered_vitis_labels = ('CAN','RIP','ROT','RU','LAB','SYL','REG','CS','PN','RL','TRI')\n",
    "\n",
    "vitis_label_colors = {lbl: c for lbl, c in zip(ordered_vitis_labels, colours)}\n",
    "\n",
    "tab20bcols = sns.color_palette('tab20b', 20)\n",
    "tab20ccols = sns.color_palette('tab20c', 20)\n",
    "tab20cols = sns.color_palette('tab20', 20)\n",
    "tab10cols = sns.color_palette('tab10', 10)\n",
    "dark2cols = sns.color_palette('Dark2', 8)\n",
    "\n",
    "vitis_label_colors['RU'] = tab20bcols[8]\n",
    "vitis_label_colors['CAN'] = tab20ccols[5]\n",
    "vitis_label_colors['REG'] = tab10cols[3]\n",
    "\n",
    "for name in datasets:\n",
    "    if name.startswith('GD'):\n",
    "        datasets[name]['label_colors'] = vitis_label_colors\n",
    "        datasets[name]['sample_colors'] = [vitis_label_colors[lbl] for lbl in datasets[name]['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.palplot(vitis_label_colors.values())\n",
    "new_ticks = plt.xticks(range(len(ordered_vitis_labels)), ordered_vitis_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 yeast strains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize label colors for 5 yeast strains\n",
    "\n",
    "colours = sns.color_palette('Set1', 5)\n",
    "yeast_classes = datasets['YD']['classes']\n",
    "yeast_label_colors = {lbl: c for lbl, c in zip(yeast_classes, colours)}\n",
    "datasets['YD']['label_colors'] = yeast_label_colors\n",
    "datasets['YD']['sample_colors'] = [yeast_label_colors[lbl] for lbl in datasets['YD']['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.palplot(yeast_label_colors.values())\n",
    "new_ticks = plt.xticks(range(len(yeast_classes)), yeast_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 classes of Vitis types (wild and _vinifera_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize label colors for 2 types of Vitis varieties\n",
    "\n",
    "colours = [vitis_label_colors['SYL'], vitis_label_colors['TRI']]\n",
    "vitis_type_classes = datasets['vitis_types']['classes']\n",
    "vitis_types_label_colors = {lbl: c for lbl, c in zip(vitis_type_classes, colours)}\n",
    "datasets['vitis_types']['label_colors'] = vitis_types_label_colors\n",
    "datasets['vitis_types']['sample_colors'] = [vitis_types_label_colors[lbl] for lbl in datasets['vitis_types']['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.palplot(datasets['vitis_types']['label_colors'].values())\n",
    "new_ticks = plt.xticks(range(len(datasets['vitis_types']['classes'])), datasets['vitis_types']['classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 HD classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize label colors for 2 HD classes\n",
    "\n",
    "colours = sns.color_palette('Set1', 2)\n",
    "hd_label_colors = {lbl: c for lbl, c in zip(datasets['HD']['classes'], colours)}\n",
    "datasets['HD']['label_colors'] = hd_label_colors\n",
    "datasets['HD']['sample_colors'] = [hd_label_colors[lbl] for lbl in datasets['HD']['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.palplot(hd_label_colors.values())\n",
    "new_ticks = plt.xticks(range(len(datasets['HD']['classes'])), datasets['HD']['classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples and respective target labels of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def styled_sample_labels(sample_names, sample_labels, label_colors):\n",
    "\n",
    "    meta_table = pd.DataFrame({'label': sample_labels,\n",
    "                               'sample': sample_names}).set_index('sample').T\n",
    "\n",
    "    def apply_label_color(val):\n",
    "        red, green, blue = label_colors[val]\n",
    "        red, green, blue = int(red*255), int(green*255), int(blue*255)   \n",
    "        hexcode = '#%02x%02x%02x' % (red, green, blue)\n",
    "        css = f'background-color: {hexcode}'\n",
    "        return css\n",
    "    \n",
    "    return meta_table.style.applymap(apply_label_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = mtl.parse_data(datasets['GD_class2']['data'], labels_loc='label')\n",
    "y = datasets['GD_class2']['target']\n",
    "label_colors = datasets['GD_class2']['label_colors']\n",
    "s = styled_sample_labels(parsed.sample_names, y, label_colors)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = mtl.parse_data(datasets['YD']['data'])\n",
    "y = datasets['YD']['target']\n",
    "label_colors = datasets['YD']['label_colors']\n",
    "s = styled_sample_labels(parsed.sample_names, y, label_colors)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = mtl.parse_data(datasets['vitis_types']['data'], labels_loc='label')\n",
    "y = datasets['vitis_types']['target']\n",
    "label_colors = datasets['vitis_types']['label_colors']\n",
    "s = styled_sample_labels(parsed.sample_names, y, label_colors)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = mtl.parse_data(datasets['HD']['data'])\n",
    "y = datasets['HD']['target']\n",
    "label_colors = datasets['HD']['label_colors']\n",
    "s = styled_sample_labels(parsed.sample_names, y, label_colors)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Colors for the pre-treatments / sMDiN analysis metrics for the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize colors for the intensity-based pre-treatment and analysis metrics of sample MDiNs\n",
    "treatments = ('IDT', 'Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMBDI', 'GCD11')\n",
    "\n",
    "treat_colors = tab10cols[:4]\n",
    "treat_colors.extend(tab20cols[8:10])\n",
    "treat_colors.append(tab10cols[5])\n",
    "treatment_colors = {lbl: c for lbl, c in zip(treatments, treat_colors)}\n",
    "\n",
    "sns.palplot(treatment_colors.values())\n",
    "new_ticks = plt.xticks(range(len(treatment_colors)), treatment_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Statistical Analysis - Permutation Tests\n",
    "\n",
    "The Supervised Statistical Analysis methods used will be Random Forest and PLS-DA.\n",
    "\n",
    "The performance of the classifiers will be evaluated by their predictive **accuracy** (which will always be estimated by internal stratified 3-fold cross-validation or 5-fold cross-validation in `vitis_types` and in `HD`).\n",
    "\n",
    "Each method will be applied to the differently-treated datasets for each of the benchmark datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dictionaries in iter_fold_splits for the 5 sMDiN analysis (not created before, since there was no\n",
    "# danger of data leakage, each network analysis is independent from network to network)\n",
    "for name, ds in datasets.items():\n",
    "    \n",
    "    ds_iter = ds['iter_fold_splits']\n",
    "\n",
    "    for itr in range(len(ds_iter.keys())):\n",
    "        for fold in ds_iter[itr+1]['train'].keys():\n",
    "            for treat in ('Degree', 'Betweenness', 'Closeness', 'MDBI', 'GCD11'):\n",
    "\n",
    "                ds_iter[itr+1]['train'][fold][treat] = ds[treat].loc[ds_iter[itr+1]['train'][fold]['data'].index]\n",
    "                ds_iter[itr+1]['test'][fold][treat] = ds[treat].loc[ds_iter[itr+1]['test'][fold]['data'].index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Tests (Very Slow)\n",
    "\n",
    "Permutation tests is based on shuffling the labels of the different samples, shuflling the groups where they belong with the intent to see if the classifier tested, whether it is Random Forest or PLS-DA found a significant class structure in the data - assess the significance of the predictive accuracy results. \n",
    "\n",
    "For that a random k-fold cross-validation is performed on the original dataset (to serve as a comparation point) and on X permutations of datasets with labels randomly shuffled around. The models are evaluated by their predictive accuracies. \n",
    "\n",
    "The empirical p-value is given by (the number of times the permutation accuracy was bigger than the random k-fold cross-validation made with the original dataset + 1) / (number of permutations + 1) (source: Ojala and Garriga, 2010).\n",
    "\n",
    "Ojala M, Garriga GC. Permutation Tests for Studying Classifier Performance. In: 2009 Ninth IEEE International Conference on Data Mining. ; 2009:908-913. doi:10.1109/ICDM.2009.108\n",
    "\n",
    "Histograms with the prediction accuracy of the different permutations were plotted and compared to the accuracy got with the original dataset.\n",
    "\n",
    "### Permutation Tests - Random Forests\n",
    "\n",
    "Use of `permutation_RF` function from multianalysis.py. See details about the application of this function in the multianalysis.py file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `GENERATE = True` to perform permutation tests and persist results in json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = True #False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_RF(dataset, iter_num=100, n_trees=200, seed=None):\n",
    "    \"\"\"Performs permutation test n times of a dataset for Random Forest classifiers giving its predictive accuracy (estimated by\n",
    "    stratified k-fold cross-validation) for the original and all permutations made and respective p-value.\n",
    "\n",
    "       dataset: dictionary, dataset storage.\n",
    "       iter_num: int (default - 100); number of permutations made.\n",
    "       n_trees: int (default - 200); number of trees in each Random Forest.\n",
    "\n",
    "       Returns: (scalar, list of scalars, scalar);\n",
    "        estimated predictive accuracy of the non-permuted Random Forest model,\n",
    "        estimated predictive accuracy of all permuted Random Forest models,\n",
    "        p-value ((number of permutations with accuracy > original accuracy) + 1)/(number of permutations + 1).\n",
    "    \"\"\"\n",
    "    \n",
    "    # get a bit generator\n",
    "    rng = default_rng(seed)\n",
    "    \n",
    "    # Iteration 1 of the the k-fold splits is used, ensuring the same split in the data is used for all permutations\n",
    "    ds_iter = dataset['iter_fold_splits']\n",
    "    \n",
    "    # Setting up variables for result storing\n",
    "    Perm = []\n",
    "    \n",
    "    # Dictionary of targets to shuffle and dataframe of the data to put columns in NewC shuffled order\n",
    "    new_target = {}\n",
    "    for fold in ds_iter[1]['train'].keys():\n",
    "        new_target[fold] = ds_iter[1]['test'][fold]['target'].copy()\n",
    "    label_dict = dict(zip(dataset['data'].index, dataset['target']))\n",
    "\n",
    "    for _ in range(iter_num + 1):\n",
    "        # Number of different permutations + original dataset where Random Forest cross-validation will be made\n",
    "        # Set up targets for this iteration\n",
    "        # 1st iteration (Non-permuted model), targets stay the same because new_target dict hasn't been shuffled yet\n",
    "        for tg in new_target:\n",
    "            for label in range(len(new_target[tg])):\n",
    "                label_dict[ds_iter[1]['test'][tg]['data'].index[label]] = new_target[tg][label]\n",
    "        \n",
    "        perm = []\n",
    "        \n",
    "        # Repeat for each of the k groups the random forest model fit and classification\n",
    "        for fold in ds_iter[1]['train'].keys():\n",
    "            \n",
    "            # Setup the permutated train target for fitting the random forest\n",
    "            train_target = [label_dict[sample] for sample in ds_iter[1]['train'][fold]['data'].index]\n",
    "            \n",
    "            # Random Forest setup and fit\n",
    "            rf = skensemble.RandomForestClassifier(n_estimators=n_trees)\n",
    "            rf.fit(ds_iter[1]['train'][fold][treatment], train_target)\n",
    "            \n",
    "            # Compute performance\n",
    "            perm.append(rf.score(ds_iter[1]['test'][fold][treatment], new_target[fold])) # Prediction Accuracy\n",
    "\n",
    "        # Shuffle target labels for each stratified k-fold - 1 permutation of the columns (leads to permutation of labels)\n",
    "        for tg in new_target:\n",
    "            rng.shuffle(new_target[tg])\n",
    "\n",
    "        # Appending K-fold cross-validation predictive accuracy\n",
    "        Perm.append(np.mean(perm))\n",
    "\n",
    "    # Taking out K-fold cross-validation accuracy for the non-shuffled (labels) dataset and p-value calculation\n",
    "    CV = Perm[0] # Non-permuted dataset results - Perm [0]\n",
    "    pvalue = (sum(Perm[1:] >= Perm[0]) + 1) / (iter_num + 1)\n",
    "\n",
    "    return CV, Perm[1:], pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(16)\n",
    "if GENERATE:\n",
    "    iter_num=500 # number of permutations\n",
    "\n",
    "    permuts_RF = []\n",
    "\n",
    "    to_permute = [name for name in datasets]# if 'global2' in name]\n",
    "    for name in to_permute:\n",
    "        for treatment in ('IDT', 'Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11'):\n",
    "            dataset = datasets[name]\n",
    "            # Choice based on prior results on which treatment tends to be better for the dataset/classifier combination\n",
    "            # Based on the supervised analysis notebook\n",
    "            if treatment == 'IDT':\n",
    "                if name == 'HD':\n",
    "                    treatment = 'NGP_RF'\n",
    "                else:\n",
    "                    treatment = 'NGP'\n",
    "\n",
    "            print(f'{iter_num} permutations (Random Forest) for {name} with treatment {treatment}', end=' ...')\n",
    "\n",
    "            start = perf_counter()\n",
    "            permutations = permutation_RF(dataset, iter_num=iter_num, n_trees=100, seed=16)\n",
    "            \n",
    "            if treatment in ('NGP', 'NGP_RF'):\n",
    "                res = {'dataset': name, 'treatment': 'IDT',\n",
    "                       'non_permuted_CV': permutations[0],\n",
    "                       'permutations': permutations[1],\n",
    "                       'p-value': permutations[2]}   \n",
    "            else:\n",
    "                res = {'dataset': name, 'treatment': treatment,\n",
    "                       'non_permuted_CV': permutations[0],\n",
    "                       'permutations': permutations[1],\n",
    "                       'p-value': permutations[2]}       \n",
    "            permuts_RF.append(res)\n",
    "            end = perf_counter()\n",
    "            pvalue = permutations[2]\n",
    "            print(f'Done! took {(end - start):.3f} s, p-value = {pvalue}')\n",
    "    \n",
    "    # Store in json file\n",
    "    fname = 'store_files/permuts_rf.json'\n",
    "    with open(fname, \"w\", encoding='utf8') as write_file:\n",
    "        json.dump(permuts_RF, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in json file\n",
    "fname = 'store_files/permuts_rf.json'\n",
    "with open(fname, \"w\", encoding='utf8') as write_file:\n",
    "    json.dump(permuts_RF, write_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation Tests - PLS-DA\n",
    "\n",
    "Use of `permutation_PLSDA` function from multianalysis.py. See details about the application of this function in the multianalysis.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_PLSDA(dataset, n_comp=10, iter_num=100, encode2as1vector=True, seed=None):\n",
    "    \"\"\"Performs permutation test n times of a dataset for PLS-DA classifiers giving its predictive accuracy (estimated by\n",
    "    stratified k-fold cross-validation) for the original and all permutations made and respective p-value.\n",
    "\n",
    "       dataset: dictionary, dataset storage.\n",
    "       n_comp: integer; number of components to use in PLS-DA.\n",
    "       iter_num: int (default - 100); number of permutations made (times labels are shuffled).\n",
    "\n",
    "       Returns: (scalar, list of scalars, scalar);\n",
    "        estimated predictive accuracy of the non-permuted PLS-DA model,\n",
    "        estimated predictive accuracy of all permuted PLS-DA models,\n",
    "        p-value ((number of permutations with accuracy > original accuracy) + 1)/(number of permutations + 1).\n",
    "    \"\"\"\n",
    "    \n",
    "    # get a bit generator\n",
    "    rng = default_rng(seed)\n",
    "    \n",
    "    # Iteration 1 of the the k-fold splits is used, ensuring the same split in the data is used for all permutations\n",
    "    ds_iter = dataset['iter_fold_splits']\n",
    "    \n",
    "    # list to store results\n",
    "    Accuracy = []\n",
    "\n",
    "    # Dictionary of targets to shuffle and dataframe of the data to put columns in NewC shuffled order\n",
    "    new_target = {}\n",
    "    for fold in ds_iter[1]['train'].keys():\n",
    "        new_target[fold] = ds_iter[1]['test'][fold]['target'].copy()\n",
    "    label_dict = dict(zip(dataset['data'].index, dataset['target']))\n",
    "\n",
    "    # Number of permutations + dataset with non-shuffled labels equal to iter_num + 1\n",
    "    for i in range(iter_num + 1):\n",
    "        # Number of different permutations + original dataset where Random Forest cross-validation will be made\n",
    "        # Set up targets for this iteration\n",
    "        # 1st iteration (Non-permuted model), targets stay the same because new_target dict hasn't been shuffled yet\n",
    "        for tg in new_target:\n",
    "            for label in range(len(new_target[tg])):\n",
    "                label_dict[ds_iter[1]['test'][tg]['data'].index[label]] = new_target[tg][label]\n",
    "    \n",
    "        # Setting up variables for results of the application of k-fold cross-validated PLS-DA\n",
    "        nright = 0\n",
    "\n",
    "        # Repeating for each of the n groups\n",
    "        for fold in ds_iter[1]['train'].keys():\n",
    "            \n",
    "            # Setup the permutated train target for fitting the random forest\n",
    "            train_target = [label_dict[sample] for sample in ds_iter[1]['train'][fold]['data'].index]\n",
    "            \n",
    "            train_group_len = len(train_target)\n",
    "            labels = train_target + new_target[fold]\n",
    "            unique_labels = list(pd.unique(labels))\n",
    "            is1vector = len(unique_labels) == 2 and encode2as1vector\n",
    "            matrix = ma._generate_y_PLSDA(labels, unique_labels, is1vector)\n",
    "            \n",
    "            if is1vector:\n",
    "                # keep a copy to use later\n",
    "                target1D = matrix.copy()\n",
    "                correct = target1D[train_group_len:]\n",
    "                y_train, y_test = matrix[:train_group_len], matrix[train_group_len:]\n",
    "            else:\n",
    "                y_train, y_test = matrix.iloc[:train_group_len], matrix.iloc[train_group_len:]\n",
    "            \n",
    "            # plsda model building for each of the k stratified groups made\n",
    "            plsda = PLSRegression(n_components=n_comp, scale=False)\n",
    "            # Fitting the model\n",
    "            plsda.fit(X=ds_iter[1]['train'][fold][treatment], Y=y_train)\n",
    "\n",
    "            # Predictions the test group\n",
    "            y_pred = plsda.predict(ds_iter[1]['test'][fold][treatment])\n",
    "\n",
    "            # Decision rule for classification\n",
    "            # Decision rule chosen: sample belongs to group where it has max y_pred (closer to 1)\n",
    "            # In case of 1,0 encoding for two groups, round to nearest integer to compare\n",
    "\n",
    "            if not is1vector:\n",
    "                for i in range(len(y_pred)):\n",
    "                    if list(y_test.iloc[i, :]).index(max(y_test.iloc[i, :])) == np.argmax(\n",
    "                        y_pred[i]\n",
    "                    ):\n",
    "                        nright += 1  # Correct prediction\n",
    "            else:\n",
    "                rounded = np.round(y_pred)\n",
    "                for i in range(len(y_pred)):\n",
    "                    if rounded[i] == correct[i]:\n",
    "                        nright += 1  # Correct prediction\n",
    "\n",
    "\n",
    "        # Calculate accuracy for this iteration\n",
    "        Accuracy.append(nright / len(labels))\n",
    "        \n",
    "        # Shuffle target labels for each stratified k-fold - 1 permutation of the columns (leads to permutation of labels)\n",
    "        for tg in new_target:\n",
    "            rng.shuffle(new_target[tg])\n",
    "\n",
    "    # Return also the K-fold cross-validation predictive accuracy for the non-shuffled dataset\n",
    "    # and the p-value\n",
    "    CV = Accuracy[0] # Predictive Accuracy of non-permuted dataset PLS-DA model - Accuracy[0]\n",
    "    pvalue = (\n",
    "        sum( [Accuracy[i] for i in range(1, len(Accuracy)) if Accuracy[i] >= Accuracy[0]] ) + 1\n",
    "    ) / (iter_num + 1)\n",
    "\n",
    "    return CV, Accuracy[1:], pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "np.random.seed(16)\n",
    "if GENERATE:\n",
    "    iter_num=500\n",
    "\n",
    "    permuts_PLSDA = []\n",
    "\n",
    "    to_permute = [name for name in datasets] # if 'global2' in name]\n",
    "    for name in to_permute:\n",
    "        for treatment in ('IDT', 'Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11'):\n",
    "            dataset = datasets[name]\n",
    "            # Choice based on prior results on which treatment tends to be better for the dataset/classifier combination\n",
    "            # Based on the supervised analysis notebook\n",
    "            if treatment == 'IDT':\n",
    "                treatment = 'NGP'\n",
    "\n",
    "            print(f'Permutation test (PLS-DA) for {name} with treatment {treatment}', end=' ...')\n",
    "            \n",
    "            if name.startswith('GD'):\n",
    "                n_comp = 10\n",
    "            elif name.startswith('HD'):\n",
    "                n_comp = 10\n",
    "            else:\n",
    "                n_comp = 6\n",
    "\n",
    "            if treatment == 'MDBI':\n",
    "                n_comp = 4\n",
    "            elif treatment == 'MDBI':\n",
    "                n_comp = 6\n",
    "\n",
    "            start = perf_counter()\n",
    "            permutations = permutation_PLSDA(dataset, n_comp=n_comp, iter_num=iter_num)\n",
    "            res = {'dataset': name, 'treatment': treatment,\n",
    "                   'non_permuted_CV': permutations[0],\n",
    "                   'permutations': permutations[1],\n",
    "                   'p-value': permutations[2]}\n",
    "            permuts_PLSDA.append(res)\n",
    "            end = perf_counter()\n",
    "            pvalue = permutations[2]\n",
    "            print(f'Done! took {(end - start):.3f} s, p-value = {pvalue:10.5f}')\n",
    "            \n",
    "    # Store in json file\n",
    "    fname = 'store_files/permuts_plsda.json'\n",
    "    with open(fname, \"w\", encoding='utf8') as write_file:\n",
    "        json.dump(permuts_PLSDA, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get data from json file - random forests\n",
    "fname = 'store_files/permuts_rf.json'\n",
    "with open(fname, \"r\", encoding='utf8') as read_file:\n",
    "    permuts_RF = json.load(read_file)\n",
    "\n",
    "for p in permuts_RF:\n",
    "    print(f\"{p['dataset']:<20}{p['treatment']:<8}{p['p-value']:10.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from json file - PLS-DA\n",
    "fname = 'store_files/permuts_plsda.json'\n",
    "with open(fname, \"r\", encoding='utf8') as read_file:\n",
    "    permuts_PLSDA = json.load(read_file)\n",
    "\n",
    "for p in permuts_PLSDA:\n",
    "    print(f\"{p['dataset']:<20}{p['treatment']:<8}{p['p-value']:10.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the Permutations test results - Histograms\n",
    "\n",
    "Nº Occurences (of the permutations) vs CV prediction acuracy - The distribution of average prediction accuracy of X permutations\n",
    "\n",
    "1st Figure - Random Forest\n",
    "\n",
    "2nd Figure - PLS-DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "        f, axes = plt.subplots(5, 7, figsize = (16,10), sharey='row', sharex='col')\n",
    "        colors = treat_colors\n",
    "        ylim = [0,200]\n",
    "        treatments = ['IDT', 'Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11']\n",
    "        \n",
    "        for row, dskey in enumerate(datasets):\n",
    "\n",
    "            to_plot = [p for p in permuts_RF if p['dataset'] == dskey]\n",
    "\n",
    "            n_labels = len(datasets[dskey]['target'])\n",
    "            n_bins = 34 if dskey in ('vitis_types', 'HD') else 16\n",
    "            \n",
    "            if dskey == 'vitis_types':\n",
    "                ylim = [0,100]\n",
    "            else:\n",
    "                ylim = [0,200]\n",
    "\n",
    "            for ax, p, tname, color in zip(axes[row].ravel(), to_plot, treatments, colors):\n",
    "                ax.hist(np.array(p['permutations'])*100, range=(0, 100.01), label=name + ' Permutations',\n",
    "                        bins=n_bins, edgecolor='black', color=color)\n",
    "                #ax.axvline(p['non_permuted_CV']*100)\n",
    "\n",
    "                ax.plot(2 * [p['non_permuted_CV'] * 100], ylim, '-', linewidth=3, color=color, #alpha = 0.5,\n",
    "                         label=name + ' (pvalue %.5f)' % p['p-value'], solid_capstyle='round')\n",
    "\n",
    "                props = dict(boxstyle='round', facecolor='white', alpha=1)\n",
    "                \n",
    "                if dskey != 'vitis_types':\n",
    "                    ax.text(95, 210, 'p-value = %.3f' % p['p-value'], bbox=props, ha='right', fontsize='small')\n",
    "                    ax.set_title(f\"{datasets[dskey]['name']}, {tname}\", color=color)\n",
    "                    ax.set_ylim(0,260)\n",
    "                else:\n",
    "                    ax.text(95, 105, 'p-value = %.3f' % p['p-value'], bbox=props, ha='right', fontsize='small')\n",
    "                    ax.set_title(f\"{datasets[dskey]['name']}, {tname}\", color=color)\n",
    "                    ax.set_ylim(0,125)\n",
    "\n",
    "        f.text(0.5, 0.015, 'CV Prediction Accuracy (%)', ha='center', va='top')\n",
    "        f.text(0.008, 0.6, 'Nº Occurrences', ha='center', va='top',rotation=90)\n",
    "        \n",
    "        f.suptitle(f'Permutation tests for Random Forests')\n",
    "        plt.tight_layout()\n",
    "        f.savefig('images/permutations_RF.pdf', dpi=300)\n",
    "        f.savefig('images/permutations_RF.jpg', dpi=300)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "        f, axes = plt.subplots(5, 7, figsize = (16,10), sharey='row', sharex='col')\n",
    "        colors = treat_colors\n",
    "        ylim = [0,200]\n",
    "        treatments = ['IDT', 'Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11']\n",
    "        \n",
    "        for row, dskey in enumerate(datasets):\n",
    "\n",
    "            to_plot = [p for p in permuts_PLSDA if p['dataset'] == dskey]\n",
    "\n",
    "            n_labels = len(datasets[dskey]['target'])\n",
    "            \n",
    "            n_bins = 34 if dskey in ('vitis_types', 'HD') else 16\n",
    "            \n",
    "            if dskey == 'vitis_types':\n",
    "                ylim = [0,100]\n",
    "            else:\n",
    "                ylim = [0,200]\n",
    "\n",
    "\n",
    "            for ax, p, tname, color in zip(axes[row].ravel(), to_plot, treatments, colors):\n",
    "                ax.hist(np.array(p['permutations'])*100, range=(0, 100.01), label=name + ' Permutations',\n",
    "                        bins=n_bins, edgecolor='black', color=color)\n",
    "                #ax.axvline(p['non_permuted_CV']*100)\n",
    "\n",
    "                ax.plot(2 * [p['non_permuted_CV'] * 100], ylim, '-', linewidth=3, color=color, #alpha = 0.5,\n",
    "                         label=name + ' (pvalue %.5f)' % p['p-value'], solid_capstyle='round')\n",
    "\n",
    "                props = dict(boxstyle='round', facecolor='white', alpha=1)\n",
    "                \n",
    "                if dskey != 'vitis_types':\n",
    "                    ax.text(95, 210, 'p-value = %.3f' % p['p-value'], bbox=props, ha='right', fontsize='small')\n",
    "                    ax.set_title(f\"{datasets[dskey]['name']}, {tname}\", color=color)\n",
    "                    ax.set_ylim(0,270)\n",
    "                else:\n",
    "                    ax.text(95, 105, 'p-value = %.3f' % p['p-value'], bbox=props, ha='right', fontsize='small')\n",
    "                    ax.set_title(f\"{datasets[dskey]['name']}, {tname}\", color=color)\n",
    "                    ax.set_ylim(0,125)\n",
    "\n",
    "        f.text(0.5, 0.015, 'CV Prediction Accuracy (%)', ha='center', va='top')\n",
    "        f.text(0.008, 0.6, 'Nº Occurrences', ha='center', va='top',rotation=90)\n",
    "        \n",
    "        \n",
    "        f.suptitle(f'Permutation tests for PLS-DA')\n",
    "        plt.tight_layout()\n",
    "        f.savefig('images/permutations_PLSDA.pdf', dpi=300)\n",
    "        f.savefig('images/permutations_PLSDA.jpg', dpi=300)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save results as an Excel Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuts_PLSDA[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 0\n",
    "permut_table = pd.DataFrame(columns=['Dataset', 'Treatment', 'Classifier', 'p-value'])\n",
    "for i in permuts_RF:\n",
    "    name = datasets[i['dataset']]['name']\n",
    "\n",
    "    permut_table.loc[l] = (name, i['treatment'], 'RF', i['p-value'])\n",
    "    l = l+1\n",
    "\n",
    "for i in permuts_PLSDA:\n",
    "    name = datasets[i['dataset']]['name']\n",
    "\n",
    "    permut_table.loc[l] = (name, i['treatment'], 'PLS-DA', i['p-value'])\n",
    "    l = l+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permut_table.to_excel('Table S2_Perm.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
