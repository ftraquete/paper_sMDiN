{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Mass-Difference Networks in Metabolomics Data Analysis\n",
    "\n",
    "Notebook to support the study on the application of **Sample M**ass-**Di**fference **N**etworks as a highly specific competing form of pre-processing procedure for high-resolution metabolomics data.\n",
    "\n",
    "Mass-Difference Networks are focused into making networks from a list of masses. Each _m/z_ will represent a node. Nodes will be connected if the difference in their masses can be associated to a simple chemical reaction (enzymatic or non-enzymatic) that led to a change in the elemental composition of its metabolite.\n",
    "\n",
    "The set of mass differences used to build said networks are called a set of MDBs - Mass-Difference-based Building block.\n",
    "\n",
    "This is notebook `paper_sMDiNs_supervised.ipynb`\n",
    "\n",
    "\n",
    "## Organization of the Notebook\n",
    "\n",
    "- Loading up pre-processed and pre-treated datasets databases with intensity-based pre-treated data and data from sMDiNs analyses.\n",
    "- **Random Forest - optimization, predictive accuracy and important features: comparison after aplication of different pre-treatment procedures.**\n",
    "- **PLS-DA - optimization, predictive accuracy and important features: comparison after aplication of different pre-treatment procedures.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Needed Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.spatial.distance as dist\n",
    "import scipy.cluster.hierarchy as hier\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import ticker\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.ensemble as skensemble\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import (mean_squared_error, r2_score, roc_auc_score, roc_curve, auc)\n",
    "\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from collections import namedtuple\n",
    "\n",
    "# Metabolinks package\n",
    "import metabolinks as mtl\n",
    "import metabolinks.transformations as transf\n",
    "\n",
    "# Python files in the repository\n",
    "import multianalysis as ma\n",
    "from elips import plot_confidence_ellipse\n",
    "\n",
    "# json for persistence\n",
    "import json\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of dataset records\n",
    "\n",
    "`datasets` is the global dict that holds all data sets. It is a **dict of dict's**.\n",
    "\n",
    "Each data set is **represented as a dict**.\n",
    "\n",
    "Each record has the following fields (keys):\n",
    "\n",
    "- `name`: the table/figure name of the data set\n",
    "- `source`: the biological source for each dataset\n",
    "- `mode`: the aquisition mode\n",
    "- `alignment`: the alignment used to generate the data matrix\n",
    "- `data`: the data matrix\n",
    "- `target`: the sample labels, possibly already integer encoded\n",
    "- `MDiN`: Mass-Difference Network - Not present here, only on sMDiNsAnalysis notebook\n",
    "- `<treatment name>`: transformed data matrix / network. These treatment names can be\n",
    "    - `Ionly`: missing value imputed data by 1/5 of the minimum value in each sample in the dataset, only\n",
    "    - `NGP`: normalized, glog transformed and Pareto scaled\n",
    "    - `Ionly_RF`: missing value imputed data by random forests, only\n",
    "    - `NGP_RF`: normalized, glog transformed and Pareto scaled\n",
    "    - `IDT`: `NGP_RF` or `NGP` - Intensity-based Data pre-Treatment chosen as comparison based on which of the two performed better for each dataset and each statistical method\n",
    "    - `sMDiN`: Sample Mass-Difference Networks - Not present here, only on sMDiNsAnalysis notebook\n",
    "       \n",
    "- `<sMDiN analysis name>`: data matrix from nework analysis of MDiNs - Not in this notebook\n",
    "    - `Degree`: degree analysis of each sMDiN\n",
    "    - `Betweenness`: betweenness centrality analysis of each sMDiN\n",
    "    - `Closeness`: closeness centrality of analysis of each sMDiN\n",
    "    - `MDBI`: analysis on the impact of each MDB (Mass-Difference based building-block) on building each sMDiN\n",
    "    - `GCD11`: Graphlet Correlation Distance of 11 different orbits (maximum of 4-node graphlets) between each sMDiN.\n",
    "    - `WMDBI`: an alternative calculation of MDBI using the results from the degree analysis.\n",
    "\n",
    "- `iter_fold_splits`: contains nested dicts that identify and contain each transformed training and testing groups data matrices with their respective iteration, training/test, fold number and one of the previously mentioned data pre-treatments\n",
    "- `train`: specific to the HD dataset; contains a set of the different pre-treatments and sMDin analysis mentioned and a target based on the training set defined for HD\n",
    "- `test`: specific to the HD dataset; contains a set of the different pre-treatments and sMDin analysis mentioned and a target based on the external test set defined for HD\n",
    "\n",
    "\n",
    "The keys of `datasets` may be shared with dicts holding records resulting from comparison analysis.\n",
    "\n",
    "Here are the keys (and respective names) of datasets used in this study:\n",
    "\n",
    "- GD_neg_global2 (GDg2-)\n",
    "- GD_neg_class2 (GDc2-)\n",
    "- YD (YD)\n",
    "- vitis_types (GD types)\n",
    "- HD (HD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Pre-Treatment\n",
    "\n",
    "For information on the **commonly used intensity based data pre-treatments** and about the **benchmark datasets**, see notebook `paper_sMDiNs_database_prep.ipynb`.\n",
    "\n",
    "For information on the **building** and the different **network analysis methods** used for the **Sample MDiNs** and information about the Mass-Difference-based Building blocks (**MDBs**), see notebook `paper_sMDiNs_sMDiNsAnalysis.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading datasets database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where the datasets are\n",
    "path = Path.cwd() / \"store_files\" / 'processed_data.json'\n",
    "storepath = Path.cwd() / \"store_files\" / 'processed_data.h5'\n",
    "with pd.HDFStore(storepath) as store:\n",
    "    \n",
    "    # Read into a dictionary not DataFrame data\n",
    "    with open(path, encoding='utf8') as read_file:\n",
    "        datasets = json.load(read_file)\n",
    "    \n",
    "    # Add DataFrame data to dict\n",
    "    for dskey, dataset in datasets.items():\n",
    "        dataset['iter_fold_splits'] = {}\n",
    "        if dskey == 'HD':\n",
    "            dataset['train'] = {}\n",
    "            dataset['test'] = {}\n",
    "        for key in dataset:\n",
    "            # Created right before\n",
    "            if 'iter_fold_splits' == key:\n",
    "                continue\n",
    "            value = dataset[key]\n",
    "            if isinstance(value, str) and value.startswith(\"INSTORE\"):\n",
    "                storekey = value.split(\"_\", 1)[1]\n",
    "                #print(storekey)\n",
    "                # Load the data from 'iter_fold_splits' carefully restoring the nested dictionaries\n",
    "                if len(storekey.split(\"AA_\")) > 1: # This separation was made to identify the 'iter_fold_splits' data\n",
    "                    dictkeys = (storekey.split(\"AA_\")[1]).split('_',3)\n",
    "                    # Create nested dicts\n",
    "                    if int(dictkeys[0]) not in dataset['iter_fold_splits'].keys():\n",
    "                        dataset['iter_fold_splits'][int(dictkeys[0])] = {}\n",
    "                    if dictkeys[1] not in dataset['iter_fold_splits'][int(dictkeys[0])].keys():\n",
    "                        dataset['iter_fold_splits'][int(dictkeys[0])][dictkeys[1]] = {}\n",
    "                    if int(dictkeys[2]) not in dataset['iter_fold_splits'][int(dictkeys[0])][dictkeys[1]].keys():\n",
    "                        dataset['iter_fold_splits'][int(dictkeys[0])][dictkeys[1]][int(dictkeys[2])] = {}\n",
    "                    dataset['iter_fold_splits'][int(dictkeys[0])][dictkeys[1]][int(dictkeys[2])][dictkeys[3]] = store[storekey]\n",
    "                \n",
    "                # Load the data from 'train' and 'test' from HD dataset keys carefully restoring the nested dictionaries\n",
    "                elif len(storekey.split(\"TTS_\")) > 1:\n",
    "                    dictkeys = ((storekey.split(\"TTS_\")[0]).split('_')[-1], storekey.split(\"TTS_\")[1])#.split('_',2)\n",
    "                    dataset[dictkeys[0]][dictkeys[1]] = store[storekey]\n",
    "                # Normal DataFrames\n",
    "                else:\n",
    "                    dataset[key] = store[storekey]\n",
    "\n",
    "            # convert colors to tuples, since they are read as lists from json file\n",
    "            elif key == 'label_colors':\n",
    "                dataset[key] = {lbl: tuple(c) for lbl, c in value.items()}\n",
    "            elif key == 'sample_colors':\n",
    "                dataset[key] = [tuple(c) for c in value]\n",
    "            elif key.endswith('target') and key.startswith(dskey):\n",
    "                if len(key.split(\"AA_\")) > 1: \n",
    "                    dictkeys = ((key.split(\"_\", 1)[1]).split(\"AA_\")[1]).split('_',3)\n",
    "                    dataset['iter_fold_splits'][int(dictkeys[0])][dictkeys[1]][int(dictkeys[2])][dictkeys[3]] = value\n",
    "                else:\n",
    "                    dictkeys = ((key.split(\"TTS_\")[0]).split('_')[-1], key.split(\"TTS_\")[1])#.split('_',2)\n",
    "                    dataset[dictkeys[0]][dictkeys[1]] = value\n",
    "\n",
    "# Remove extra keys\n",
    "for name, ds in datasets.items():\n",
    "    keys_to_remove = [keys for keys in ds.keys() if keys.startswith(name)]\n",
    "    for key in keys_to_remove:\n",
    "        ds.pop(key)\n",
    "\n",
    "#datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a placeholder for the Intensity-based Data pre-Treatment (IDT)\n",
    "# Chosen for each dataset and each method based on which between NGP and NGP_RF generated the best results\n",
    "for name, ds in datasets.items():\n",
    "    ds['IDT'] = ds['NGP_RF']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname = 'store_files/datasets.json'\n",
    "#with open(fname, \"r\", encoding='utf8') as read_file:\n",
    "#    datasets = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for dskey, ds in datasets.items():\n",
    "#    if dskey.startswith('YD'):\n",
    "#        ds['data'] = pd.DataFrame(ds['data']['data'], index=ds['data']['index'], columns=ds['data']['columns'])\n",
    "#        ds['original'] = ds['data']\n",
    "    \n",
    "#    else:\n",
    "#        df_idx = pd.MultiIndex.from_tuples(ds['data']['index'])\n",
    "#        df_data = pd.DataFrame(ds['data']['data'], index=df_idx, columns=ds['data']['columns'])\n",
    "#        df_data.index.set_names('label', level=0, inplace=True)\n",
    "        \n",
    "#        ds['data'] = df_data\n",
    "#        ds['original'] = df_data\n",
    "        \n",
    "    # Checkpoint to see if the data is equal\n",
    "    #assert_frame_equal(datasets[dskey]['data'], datasets2[dskey]['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Possibly Useful Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atomic masses - https://ciaaw.org/atomic-masses.htm\n",
    "#Isotopic abundances-https://ciaaw.org/isotopic-abundances.htm/https://www.degruyter.com/view/journals/pac/88/3/article-p293.xml\n",
    "# Isotopic abundances from Pure Appl. Chem. 2016; 88(3): 293â€“306,\n",
    "# Isotopic compositions of the elements 2013 (IUPAC Technical Report), doi: 10.1515/pac-2015-0503\n",
    "\n",
    "chemdict = {'H':(1.0078250322, 0.999844),\n",
    "            'C':(12.000000000, 0.988922),\n",
    "            'N':(14.003074004, 0.996337),\n",
    "            'O':(15.994914619, 0.9976206),\n",
    "            'Na':(22.98976928, 1.0),\n",
    "            'P':(30.973761998, 1.0),\n",
    "            'S':(31.972071174, 0.9504074),\n",
    "            'Cl':(34.9688527, 0.757647),\n",
    "            'F':(18.998403163, 1.0),\n",
    "            'C13':(13.003354835, 0.011078) # Carbon 13 isotope\n",
    "           }\n",
    "\n",
    "# electron mass from NIST http://physics.nist.gov/cgi-bin/cuu/Value?meu|search_for=electron+mass\n",
    "electron_mass = 0.000548579909065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemical Formula transformations (MDBs chosen)\n",
    "MDB = ['H2','CH2','CO2','O','CHOH','NCH','O(N-H-)','S','CONH','PO3H','NH3(O-)','SO3','CO', 'C2H2O', 'H2O']\n",
    "MDB_YD = ['H2','CH2','CO2','O','CHOH','NCH','O(N-H-)','S','CONH','PO3H','NH3(O-)','SO3','CO', 'C2H2O', 'H2O', \n",
    "          'C2H2O2', 'C3H4O2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colors for plots to ensure consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11 variety grapevine data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize label colors for 11 grapevine varieties\n",
    "\n",
    "colours = sns.color_palette('Blues', 3)\n",
    "colours.extend(sns.color_palette('Greens', 3))\n",
    "#colours = sns.cubehelix_palette(n_colors=6, start=2, rot=0, dark=0.2, light=.9, reverse=True)\n",
    "colours.extend(sns.color_palette('flare', 5))\n",
    "\n",
    "ordered_vitis_labels = ('CAN','RIP','ROT','RU','LAB','SYL','REG','CS','PN','RL','TRI')\n",
    "\n",
    "vitis_label_colors = {lbl: c for lbl, c in zip(ordered_vitis_labels, colours)}\n",
    "\n",
    "tab20bcols = sns.color_palette('tab20b', 20)\n",
    "tab20ccols = sns.color_palette('tab20c', 20)\n",
    "tab20cols = sns.color_palette('tab20', 20)\n",
    "tab10cols = sns.color_palette('tab10', 10)\n",
    "dark2cols = sns.color_palette('Dark2', 8)\n",
    "\n",
    "vitis_label_colors['RU'] = tab20bcols[8]\n",
    "vitis_label_colors['CAN'] = tab20ccols[5]\n",
    "vitis_label_colors['REG'] = tab10cols[3]\n",
    "\n",
    "for name in datasets:\n",
    "    if name.startswith('GD'):\n",
    "        datasets[name]['label_colors'] = vitis_label_colors\n",
    "        datasets[name]['sample_colors'] = [vitis_label_colors[lbl] for lbl in datasets[name]['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.palplot(vitis_label_colors.values())\n",
    "new_ticks = plt.xticks(range(len(ordered_vitis_labels)), ordered_vitis_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 yeast strains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize label colors for 5 yeast strains\n",
    "\n",
    "colours = sns.color_palette('Set1', 5)\n",
    "yeast_classes = datasets['YD']['classes']\n",
    "yeast_label_colors = {lbl: c for lbl, c in zip(yeast_classes, colours)}\n",
    "datasets['YD']['label_colors'] = yeast_label_colors\n",
    "datasets['YD']['sample_colors'] = [yeast_label_colors[lbl] for lbl in datasets['YD']['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.palplot(yeast_label_colors.values())\n",
    "new_ticks = plt.xticks(range(len(yeast_classes)), yeast_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 classes of Vitis types (wild and _vinifera_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize label colors for 2 types of Vitis varieties\n",
    "\n",
    "colours = [vitis_label_colors['SYL'], vitis_label_colors['TRI']]\n",
    "vitis_type_classes = datasets['vitis_types']['classes']\n",
    "vitis_types_label_colors = {lbl: c for lbl, c in zip(vitis_type_classes, colours)}\n",
    "datasets['vitis_types']['label_colors'] = vitis_types_label_colors\n",
    "datasets['vitis_types']['sample_colors'] = [vitis_types_label_colors[lbl] for lbl in datasets['vitis_types']['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.palplot(datasets['vitis_types']['label_colors'].values())\n",
    "new_ticks = plt.xticks(range(len(datasets['vitis_types']['classes'])), datasets['vitis_types']['classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 HD classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize label colors for 2 HD classes\n",
    "\n",
    "colours = sns.color_palette('Set1', 2)\n",
    "hd_label_colors = {lbl: c for lbl, c in zip(datasets['HD']['classes'], colours)}\n",
    "datasets['HD']['label_colors'] = hd_label_colors\n",
    "datasets['HD']['sample_colors'] = [hd_label_colors[lbl] for lbl in datasets['HD']['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.palplot(hd_label_colors.values())\n",
    "new_ticks = plt.xticks(range(len(datasets['HD']['classes'])), datasets['HD']['classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples and respective target labels of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def styled_sample_labels(sample_names, sample_labels, label_colors):\n",
    "\n",
    "    meta_table = pd.DataFrame({'label': sample_labels,\n",
    "                               'sample': sample_names}).set_index('sample').T\n",
    "\n",
    "    def apply_label_color(val):\n",
    "        red, green, blue = label_colors[val]\n",
    "        red, green, blue = int(red*255), int(green*255), int(blue*255)   \n",
    "        hexcode = '#%02x%02x%02x' % (red, green, blue)\n",
    "        css = f'background-color: {hexcode}'\n",
    "        return css\n",
    "    \n",
    "    return meta_table.style.applymap(apply_label_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = mtl.parse_data(datasets['GD_neg_class2']['data'], labels_loc='label')\n",
    "y = datasets['GD_neg_class2']['target']\n",
    "label_colors = datasets['GD_neg_class2']['label_colors']\n",
    "s = styled_sample_labels(parsed.sample_names, y, label_colors)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = mtl.parse_data(datasets['YD']['data'])\n",
    "y = datasets['YD']['target']\n",
    "label_colors = datasets['YD']['label_colors']\n",
    "s = styled_sample_labels(parsed.sample_names, y, label_colors)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = mtl.parse_data(datasets['vitis_types']['data'], labels_loc='label')\n",
    "y = datasets['vitis_types']['target']\n",
    "label_colors = datasets['vitis_types']['label_colors']\n",
    "s = styled_sample_labels(parsed.sample_names, y, label_colors)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = mtl.parse_data(datasets['HD']['data'])\n",
    "y = datasets['HD']['target']\n",
    "label_colors = datasets['HD']['label_colors']\n",
    "s = styled_sample_labels(parsed.sample_names, y, label_colors)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Colors for the pre-treatments / sMDiN analysis metrics for the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize colors for the intensity-based pre-treatment and analysis metrics of sample MDiNs\n",
    "treatments = ('IDT', 'Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11', 'NGP', 'NGP_RF')\n",
    "\n",
    "treat_colors = tab10cols[:4]\n",
    "treat_colors.extend(tab20cols[8:10])\n",
    "treat_colors.append(tab10cols[5])\n",
    "treat_colors.extend(tab20cols[:2])\n",
    "treatment_colors = {lbl: c for lbl, c in zip(treatments, treat_colors)}\n",
    "\n",
    "sns.palplot(treatment_colors.values())\n",
    "new_ticks = plt.xticks(range(len(treatment_colors)), treatment_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Statistical Analysis\n",
    "\n",
    "The Supervised Statistical Analysis methods used will be Random Forest and PLS-DA.\n",
    "\n",
    "The performance of the classifiers will be evaluated by their predictive **accuracy** (which will always be estimated by internal stratified 3-fold cross-validation or 5-fold cross-validation in `vitis_types` and in `HD`). For the `HD`, an external test set comprising 30% of samples was separated from the a training set to further validate the models.\n",
    "\n",
    "Each method will be applied to the differently-treated datasets for each of the benchmark datasets.\n",
    "\n",
    "**Note**: If `Generate` is **True**, Random Forest and PLS-DA will be applied. They are always on the cell before the application.\n",
    "\n",
    "#### All supervised methods on IDT or WMDBI were applied using the iteration data in 'iter_fold_splits' of the datasets. This data has 20 iterations of different k-fold separations of the data in training and testing groups which were independently treated by these methods. Optimization methods were applied using the '1st iteration' data. For the remaining sMDiN analysis methods, the same fold separations in each iteration were also used.\n",
    "\n",
    "Functions were made using the 'iter_fold_splits' key of each benchmark dataset dict. Inside this dict, there are many nested dicts that culminate in the independently treated training and test dataset for all iterations and fold splits (for k-fold cross-validation) as well as each tested data pre-treatment. This is performed to validate our models and finding by stratified k-fold cross-validation with 20 iterations of this process being made to have more combinations of training and test samples are used to offset the small (in terms of samples per group) datasets. As such, this is a variation of the mroe general functions in `multianalysis.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dictionaries in iter_fold_splits for the 5 sMDiN analysis (not created before, since there was no\n",
    "# danger of data leakage, each network analysis is independent from network to network)\n",
    "for name, ds in datasets.items():\n",
    "    \n",
    "    ds_iter = ds['iter_fold_splits']\n",
    "\n",
    "    for itr in range(len(ds_iter.keys())):\n",
    "        for fold in ds_iter[itr+1]['train'].keys():\n",
    "            for treat in ('Degree', 'Betweenness', 'Closeness', 'MDBI', 'GCD11'):\n",
    "\n",
    "                ds_iter[itr+1]['train'][fold][treat] = ds[treat].loc[ds_iter[itr+1]['train'][fold]['data'].index]\n",
    "                ds_iter[itr+1]['test'][fold][treat] = ds[treat].loc[ds_iter[itr+1]['test'][fold]['data'].index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization of the number of trees\n",
    "\n",
    "Random Forest models with different number of trees are built to assess when the predictive accuracy of the different models stops increasing with the number of trees. Grid search of number of trees from 10 to 200 for the random forests with 5 tree interval. See where the cross-validation estimated predictive accuracy stops improving for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2967)\n",
    "if GENERATE:\n",
    "    # NOTE: for debugging\n",
    "    top_tree_in_grid=200\n",
    "    # otherwise\n",
    "    #top_tree_in_grid=200\n",
    "\n",
    "    # For each dataset, build  Random Forest models with the different number of trees\n",
    "    # and store the predictive accuracy (estimated by k-fold cross-validation)\n",
    "\n",
    "    RF_optim = {}\n",
    "    for name, dataset in datasets.items():\n",
    "        \n",
    "        if name in ('vitis_types', 'HD'):\n",
    "            cv = 5\n",
    "        else:\n",
    "            cv = 3\n",
    "        \n",
    "        # Dicionary key with the iteration/fold combinations\n",
    "        ds_iter = datasets[name]['iter_fold_splits']\n",
    "        \n",
    "        for treatment in ('NGP', 'NGP_RF', 'Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11'):\n",
    "            print('Fitting to', dataset['name'], 'pre-treatment', treatment, '...', end=' ')\n",
    "            rfname = name + ' ' + treatment\n",
    "            RF_optim[rfname] = {'dskey': name, 'dataset': dataset['name'], 'treatment':treatment}\n",
    "            \n",
    "            accuracy_scores = []\n",
    "            \n",
    "            for n_trees in range(10,top_tree_in_grid,5):\n",
    "                CV_accuracy_scores = []\n",
    "                # Fit and evaluate a Random Forest model for each fold in stratified k-fold cross validation\n",
    "                for fold in range(1,cv+1):\n",
    "                    # Random Forest setup and fit\n",
    "                    #print(ds_iter[1]['train'][fold][treatment])\n",
    "                    rf = skensemble.RandomForestClassifier(n_estimators=n_trees)\n",
    "                    rf.fit(ds_iter[1]['train'][fold][treatment], ds_iter[1]['train'][fold]['target'])\n",
    "\n",
    "                    # Compute performance\n",
    "                    CV_accuracy_scores.append(rf.score(ds_iter[1]['test'][fold][treatment], \n",
    "                                                       ds_iter[1]['test'][fold]['target'])) # Prediction Accuracy\n",
    "\n",
    "                # Average Predictive Accuracy in this iteration\n",
    "                accuracy_scores.append(np.mean(CV_accuracy_scores))\n",
    "            \n",
    "            RF_optim[rfname]['scores'] = accuracy_scores\n",
    "            RF_optim[rfname]['n_trees'] = list(range(10,top_tree_in_grid,5))\n",
    "\n",
    "            print('Done!')\n",
    "    print('writing results to file')\n",
    "    path = Path.cwd() / 'store_files' / 'RF_optim.json'\n",
    "    print(path.name)\n",
    "    with open(path, \"w\", encoding='utf8') as write_file:\n",
    "        json.dump(RF_optim, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.cwd() / 'store_files' / 'RF_optim.json'\n",
    "with open(path, \"r\", encoding='utf8') as read_file:\n",
    "    RF_optim = json.load(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots of tree number optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results and adjusting parameters of the plot\n",
    "\n",
    "def plot_RF_otimization_ntrees(RF_optim, dskey, ax=None, ylabel='', title='', ylim=(30,101)):\n",
    "    col = treat_colors[-2:] + treat_colors[1:]\n",
    "    to_plot = [optim for key, optim in RF_optim.items() if optim['dskey'] == dskey]\n",
    "    treatments = ('NGP', 'NGP_RF', 'Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11')\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    for treatment, color in zip(treatments, col):\n",
    "        for optim in to_plot:\n",
    "            if optim['treatment'] == treatment:\n",
    "                break\n",
    "        ax.plot(optim['n_trees'], [s*100 for s in optim['scores']], label=treatment, color=color)\n",
    "    ax.set(ylabel=ylabel, xlabel='Number of Trees', ylim=ylim, title=title)\n",
    "    ax.legend()\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "        f, axs = plt.subplots(3, 2, figsize=(12,15), constrained_layout=True)\n",
    "\n",
    "        for dskey, ax in zip(datasets, axs.ravel()):\n",
    "        \n",
    "            plot_RF_otimization_ntrees(RF_optim, dskey, ax=ax,\n",
    "                                       ylabel='Random Forest CV Mean Accuracy (%)',\n",
    "                                       title=datasets[dskey][\"name\"])\n",
    "\n",
    "        f.suptitle('Optimization of the number of trees')\n",
    "        axs[2][1].set_visible(False)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest models\n",
    "\n",
    "Random Forest models were built with the `RandomForestClassifier` from scikit-learn using the `RF_model_CV` modified from multianalysis.py (to accommodate our database structure) shown below.\n",
    "\n",
    "This function reads the 20 iterations and k folds stored in the data to perform k-fold cross-validation. Iterations are used to test more combinations of training and test samples to offset the small (in terms of samples per group) datasets. \n",
    "\n",
    "It then stores predictive accuracy of the models (across the iterations) and an ordered list of the most to least important features (average across the iterations) in building the model according to the Gini Importance calculated by scikit-learn of each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = True # False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF_model_CV - RF application and result extraction.\n",
    "# Altered version of RF_model_CV taking into account the treated datasets in the 'iter_fold_splits' key of each dataset dict.\n",
    "# Inside this dict, there are many nested dicts that culminate in the independently treated training and test dataset for all\n",
    "# iterations and fold splits (for k-fold cross-validation) as well as each tested data pre-treatment.\n",
    "def RF_model_CV(ds, treatment, n_trees=200):\n",
    "\n",
    "    nfeats = ds['data'].shape[1]\n",
    "    ds_iter = ds['iter_fold_splits']\n",
    "\n",
    "    # Setting up variables for result storing\n",
    "    #imp_feat = np.zeros((len(ds_iter.keys()) * len(ds_iter[1]['train'].keys()), nfeats))\n",
    "    imp_feat = {}\n",
    "    accuracy_scores = []\n",
    "    \n",
    "    # Number of times Random Forest cross-validation is made\n",
    "    # with `n_fold` randomly generated folds.\n",
    "    for itr in range(len(ds_iter.keys())):\n",
    "        \n",
    "        # To store results\n",
    "        CV_accuracy_scores = []\n",
    "\n",
    "        # Fit and evaluate a Random Forest model for each fold in stratified k-fold cross validation\n",
    "        for fold in ds_iter[itr+1]['train'].keys():\n",
    "            # Random Forest setup and fit\n",
    "            rf = skensemble.RandomForestClassifier(n_estimators=n_trees)\n",
    "            rf.fit(ds_iter[itr+1]['train'][fold][treatment], ds_iter[itr+1]['train'][fold]['target'])\n",
    "            \n",
    "            # Compute performance and important features\n",
    "            CV_accuracy_scores.append(rf.score(ds_iter[itr+1]['test'][fold][treatment], \n",
    "                                               ds_iter[itr+1]['test'][fold]['target'])) # Prediction Accuracy\n",
    "            #imp_feat[f, :] = rf.feature_importances_\n",
    "            imp_feat[str(itr+1)+'-'+str(fold)] = dict(zip(ds_iter[itr+1]['train'][fold][treatment].columns,\n",
    "                                                      rf.feature_importances_)) # Importance of each feature\n",
    "\n",
    "        # Average Predictive Accuracy in this iteration\n",
    "        accuracy_scores.append(np.mean(CV_accuracy_scores))\n",
    "    \n",
    "    # Collect and order all important features values from each Random Forest\n",
    "    imp_feat = pd.DataFrame.from_dict(imp_feat).replace({np.nan:0})\n",
    "    imp_feat_sum = (imp_feat.sum(axis=1)/ (len(ds_iter.keys()) * len(ds_iter[itr+1]['train'].keys())))\n",
    "    sorted_imp_feat = imp_feat_sum.sort_values(ascending=False)\n",
    "    imp_feat = []\n",
    "    for i in sorted_imp_feat.index:\n",
    "        imp_feat.append((i, sorted_imp_feat.loc[i]))\n",
    "\n",
    "    if len(ds_iter.keys()) == 1:\n",
    "        return {'accuracy': accuracy_scores[0], 'important_features': imp_feat}\n",
    "    else:\n",
    "        return {'accuracy': accuracy_scores, 'important_features': imp_feat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(16)\n",
    "if GENERATE:\n",
    "\n",
    "    RF_all = {}\n",
    "\n",
    "    # Application of the Random Forests for each differently-treated dataset\n",
    "    for name, dataset in datasets.items():\n",
    "        \n",
    "        # Intensity-based pre-treatments\n",
    "        IDT_res = {}\n",
    "        for treatment in ('NGP', 'NGP_RF'):\n",
    "            print(f'Fitting random forest for {name} with treatment {treatment}', end=' ...')\n",
    "            IDT_res[treatment] = {'dskey': name, 'dataset': dataset['name'], 'treatment':treatment}\n",
    "\n",
    "            fit = RF_model_CV(dataset, treatment, n_trees=100)\n",
    "            IDT_res[treatment].update(fit)\n",
    "\n",
    "            print(f'done')\n",
    "        \n",
    "        # Choose the Intensity-based Data pre-Treatment (IDT) with the highest accuracy\n",
    "        #print(np.mean(IDT_res['NGP_RF']['accuracy']), np.mean(IDT_res['NGP']['accuracy']))\n",
    "        if np.mean(IDT_res['NGP_RF']['accuracy']) >= np.mean(IDT_res['NGP']['accuracy']):\n",
    "            rfname = name + ' ' + 'IDT'\n",
    "            RF_all[rfname] = IDT_res['NGP_RF']\n",
    "            RF_all[rfname]['treatment'] = 'IDT'\n",
    "        else:\n",
    "            rfname = name + ' ' + 'IDT'\n",
    "            RF_all[rfname] = IDT_res['NGP']\n",
    "            RF_all[rfname]['treatment'] = 'IDT'\n",
    "        \n",
    "        for treatment in ('Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11'):\n",
    "            print(f'Fitting random forest for {name} with treatment {treatment}', end=' ...')\n",
    "            rfname = name + ' ' + treatment\n",
    "            RF_all[rfname] = {'dskey': name, 'dataset': dataset['name'], 'treatment':treatment}\n",
    "\n",
    "            fit = RF_model_CV(dataset, treatment, n_trees=100)\n",
    "            RF_all[rfname].update(fit)\n",
    "\n",
    "            print(f'done')    \n",
    "            \n",
    "    # Store Results\n",
    "    fname = 'store_files/RF_all.json'\n",
    "    with open(fname, \"w\", encoding='utf8') as write_file:\n",
    "        json.dump(RF_all, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read prior results\n",
    "fname = 'store_files/RF_all.json'\n",
    "with open(fname, \"r\", encoding='utf8') as read_file:\n",
    "    RF_all = json.load(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results of the Random Forest - Performance (Predictive Accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy across the iterations\n",
    "accuracies = pd.DataFrame({name: RF_all[name]['accuracy'] for name in RF_all})\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributions of Predictive Accuracies for _GDg2-_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['IDT', 'Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11']\n",
    "\n",
    "# Violin plot of the distribution of the predictive accuracy (in %) across the iterations of randomly sampled folds for each \n",
    "# differently-treated dataset.\n",
    "\n",
    "cols2keep = [col for col in accuracies.columns if 'neg_global2' in col]\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    f, ax = plt.subplots(figsize=(14,6))\n",
    "    res100 = accuracies[cols2keep] * 100\n",
    "    res100.columns = column_names\n",
    "\n",
    "    colors = treat_colors\n",
    "    sns.violinplot(data=res100, palette=colors)\n",
    "\n",
    "    plt.ylabel('Prediction Accuracy (%) - Random Forest', fontsize=13)\n",
    "    plt.ylim([25,100])\n",
    "    ax.tick_params(axis='x', which='major', labelsize = 18)\n",
    "    ax.tick_params(axis='y', which='major', labelsize = 15)\n",
    "    for ticklabel, tickcolor in zip(plt.gca().get_xticklabels(), colors):\n",
    "        ticklabel.set_color(tickcolor)\n",
    "    f.suptitle('Predictive Accuracy of Random Forest models - GD alignment global2 Negative Mode', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Predictive Accuracies of Random Forest models\n",
    "\n",
    "Error bars were built based on the standard deviation of the predictive accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_stats = pd.DataFrame({'Average accuracy': accuracies.mean(axis=0),\n",
    "                               'STD': accuracies.std(axis=0)})\n",
    "\n",
    "accuracy_stats = accuracy_stats.assign(dataset=[RF_all[name]['dataset'] for name in RF_all],\n",
    "                                       treatment=[RF_all[name]['treatment'] for name in RF_all])\n",
    "accuracy_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4 = treat_colors\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.3):\n",
    "        f, ax = plt.subplots(1, 1, figsize=(16, 6))\n",
    "        x = np.arange(len(datasets))  # the label locations\n",
    "        labels = [datasets[name]['name'] for name in datasets]\n",
    "        width = 0.1  # the width of the bars\n",
    "        for i, treatment in enumerate(('IDT', 'Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11')):\n",
    "            acc_treatment = accuracy_stats[accuracy_stats['treatment']==treatment]\n",
    "            offset = - 0.25 + i * 0.1\n",
    "            rects = ax.bar(x + offset, acc_treatment['Average accuracy'], width, label=treatment, color = p4[i])\n",
    "            ax.errorbar(x + offset, y=acc_treatment['Average accuracy'], yerr=acc_treatment['STD'],\n",
    "                        ls='none', ecolor='0.2', capsize=3)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(labels)\n",
    "        ax.set(ylabel='Average accuracy', title='', ylim=(0.3,1.03))\n",
    "        ax.text(-0.5, 0.95, 'A', weight='bold', fontsize=15)\n",
    "        ax.legend(loc='upper left', bbox_to_anchor=(0.10, 1), ncol=2, fontsize=10)\n",
    "        #f.savefig('images/RF_performance.pdf' , dpi=200)\n",
    "        #f.savefig('images/RF_performance.png' , dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curves\n",
    "\n",
    "ROC curves are computed for the `vitis_types` and `HD` classifiers only (2-class problems) using `RandomForestClassifier` from scikit-learn in the function `RF_ROC_cv` from multianalysis.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_ROC_cv(datasets, treatment, pos_label, n_trees=200, n_iter=1):\n",
    "    \"\"\"Fits and extracts Random Forest model data from the 1st iteration of fold splits saved in the dataset storage.\n",
    "       It then calculates metrics to plot a ROC curve.\"\"\"\n",
    "\n",
    "    ds_iter = datasets['iter_fold_splits']\n",
    "    \n",
    "    # Run classifier with cross-validation and plot ROC curves\n",
    "    classifier = skensemble.RandomForestClassifier(n_estimators=n_trees)\n",
    "\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "    # Iteration number cannot be bigger than the number of iterations available in storage\n",
    "    if n_iter > len(ds_iter.keys()):\n",
    "        n_iter = len(ds_iter.keys())\n",
    "    \n",
    "    # Number of times Random Forest cross-validation is made\n",
    "    # with `n_fold` randomly generated folds.\n",
    "    for itr in range(n_iter):\n",
    "        # Fit and evaluate a Random Forest model for each fold in stratified k-fold cross validation\n",
    "        for fold in ds_iter[itr+1]['train'].keys():\n",
    "            \n",
    "            # transform target labels to an array\n",
    "            train_group_len = len(ds_iter[itr+1]['train'][fold]['target'])\n",
    "            labels = ds_iter[itr+1]['train'][fold]['target'] + ds_iter[itr+1]['test'][fold]['target']\n",
    "            target = [lbl==pos_label for lbl in labels]\n",
    "            y = np.array(target, dtype=int)\n",
    "            y_train, y_test = y[:train_group_len], y[train_group_len:]\n",
    "            target = [lbl==pos_label for lbl in y]\n",
    "            \n",
    "            # Fit the rf classifier\n",
    "            classifier.fit(ds_iter[itr+1]['train'][fold][treatment], y_train)\n",
    "            \n",
    "            # Metrics for ROC curve plotting\n",
    "            scores = classifier.predict_proba(ds_iter[itr+1]['test'][fold][treatment])[:, 1]\n",
    "\n",
    "            fpr, tpr, _ = roc_curve(y_test, scores)\n",
    "\n",
    "            interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "            interp_tpr[0] = 0.0\n",
    "            tprs.append(interp_tpr)\n",
    "            aucs.append(roc_auc_score(y_test, scores))\n",
    "    \n",
    "    # Mean of every fold of the cross-validation\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "    return {'average fpr': mean_fpr, 'average tpr': mean_tpr, \n",
    "            'upper tpr': tprs_upper, 'lower trp': tprs_lower,\n",
    "            'mean AUC': mean_auc, 'std AUC': std_auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(16)\n",
    "names = ['vitis_types','HD']\n",
    "pos_labels = ['vinifera', 'Recurrence']\n",
    "resROC = {}\n",
    "\n",
    "# Perform and obtain the results for the ROC curves\n",
    "for name, pos_label in zip(names, pos_labels):\n",
    "    np.random.seed(16)\n",
    "    dataset = datasets[name]\n",
    "    #datasets[name]['IDT'] = datasets[name]['NGP']\n",
    "    y = dataset['target']\n",
    "    resROC[name] = {}\n",
    "    for treatment in ('NGP', 'NGP_RF', 'Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11'):\n",
    "        #df = dataset[treatment]\n",
    "        res = RF_ROC_cv(dataset, treatment, pos_label, n_trees=100, n_iter=20)\n",
    "        # Selecting the best out of NGP and NGP_RF intensity-based data pre-treatments based on AUC and storing as 'IDT'\n",
    "        if treatment == 'NGP':\n",
    "            res_temp = res\n",
    "        elif treatment == 'NGP_RF':\n",
    "            if res['mean AUC'] >= res_temp['mean AUC']:\n",
    "                resROC[name]['IDT'] = res\n",
    "            else:\n",
    "                resROC[name]['IDT'] = res_temp\n",
    "        # Data matrices from the network analyses of sMDiNs\n",
    "        else:\n",
    "            resROC[name][treatment] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curves \n",
    "p4 = treat_colors[:7]\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "        f, axs = plt.subplots(1, 2, figsize=(12,5), constrained_layout=True)\n",
    "        for rROC, ax in zip(resROC.values(), axs.ravel()):\n",
    "            for treatment, color in zip(rROC, p4):\n",
    "                res = rROC[treatment]\n",
    "                mean_fpr = res['average fpr']\n",
    "                mean_tpr = res['average tpr']\n",
    "                mean_auc = res['mean AUC']\n",
    "                ax.plot(mean_fpr, mean_tpr, color=color,\n",
    "                       label=f'{treatment} (AUC = {mean_auc:.3f})',\n",
    "                       lw=2, alpha=0.8)\n",
    "            ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='lightgrey', alpha=.8)\n",
    "            ax.legend()\n",
    "            ax.set_xlim(None,1)\n",
    "            ax.set_ylim(0,None)\n",
    "            ax.set(xlabel='False positive rate', ylabel='True positive rate')\n",
    "            \n",
    "        #for letter, ax in zip('AB', axs.ravel()[0:2]):\n",
    "        #    ax.text(0.88, 0.9, letter, ha='left', va='center', fontsize=15, weight='bold',\n",
    "        #            transform=ax.transAxes,\n",
    "        #            bbox=dict(facecolor='white', alpha=0.9))\n",
    "        \n",
    "        f.savefig('images/ROC_vitis.pdf', dpi=300)\n",
    "        f.savefig('images/ROC_vitis.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important feature analysis - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_impfeat_table(Imp_Feats, colnames=['Feature', 'Importance Metric']):\n",
    "    \"Transform Imp. Feat. into a table (df) with the place, name of the feature and the score of the importance metric.\"\n",
    "    Imp_Feats_Table = pd.DataFrame(columns=colnames)\n",
    "    for n in range(len(Imp_Feats)):\n",
    "        Imp_Feats_Table.loc[n+1] = Imp_Feats[n][0], Imp_Feats[n][1]\n",
    "    Imp_Feats_Table.index.name = 'Place'\n",
    "    \n",
    "    return Imp_Feats_Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDBI_RF_Imp_Feat = {}\n",
    "for dskey, ds in RF_all.items():\n",
    "    if dskey.endswith(' MDBI'):\n",
    "        name, treat = dskey.split()\n",
    "        #print(name, treat)\n",
    "        MDBI_RF_Imp_Feat[name] = build_impfeat_table(ds['important_features'], colnames=['Feature', 'Gini Imp.'])\n",
    "        \n",
    "WMDBI_RF_Imp_Feat = {}\n",
    "for dskey, ds in RF_all.items():\n",
    "    if dskey.endswith('WMDBI'):\n",
    "        name, treat = dskey.split()\n",
    "        #print(name, treat)\n",
    "        WMDBI_RF_Imp_Feat[name] = build_impfeat_table(ds['important_features'], colnames=['Feature', 'Gini Imp.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDBI_RF_Imp_Feat['vitis_types']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDBI_RF_Imp_Feat['YD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "WMDBI_RF_Imp_Feat['YD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a Heatmap of the MDB Impact data matrix obtained for the YD benchmark dataset.\n",
    "\n",
    "For visualization purposes, to compare the different MDBs that can have different magnitudes, auto-scaling was employed.\n",
    "\n",
    "### MDBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sns.heatmap\n",
    "f, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "tf = transf.FeatureScaler(method='standard')\n",
    "df = tf.fit_transform(datasets['YD']['MDBI'].loc[:,list(MDBI_RF_Imp_Feat['YD']['Feature'])])\n",
    "\n",
    "MDB_2 = MDBI_RF_Imp_Feat['YD'].loc[:,'Feature']\n",
    "\n",
    "g = sns.heatmap(df.T, xticklabels=False, yticklabels=MDB_2, cmap='PRGn', vmin=-3, vmax=3)\n",
    "g.set_yticklabels(g.get_ymajorticklabels(), fontsize = 14)\n",
    "\n",
    "# Manually specify colorbar labelling after it's been generated\n",
    "colorbar = g.collections[0].colorbar\n",
    "colorbar.ax.tick_params(labelsize=14) \n",
    "\n",
    "# thick line between the samples of different classes\n",
    "for i in range(3,15,3):\n",
    "    ax.axvline(i, color='white', lw=5)\n",
    "ax.tick_params(length=0)\n",
    "plt.text(1.5, 17.8, 'WT', ha='center', fontsize = 18, color = datasets['YD']['label_colors']['WT'])\n",
    "plt.text(4.5, 17.8, 'Î”GRE3', ha='center', fontsize = 18, color = datasets['YD']['label_colors']['Î”GRE3'])\n",
    "plt.text(7.5, 17.8, 'Î”ENO1', ha='center', fontsize = 18, color = datasets['YD']['label_colors']['Î”ENO1'])\n",
    "plt.text(10.5, 17.8, 'Î”GLO1', ha='center', fontsize = 18, color = datasets['YD']['label_colors']['Î”GLO1'])\n",
    "plt.text(13.5, 17.8, 'Î”GLO2', ha='center', fontsize = 18, color = datasets['YD']['label_colors']['Î”GLO2'])\n",
    "#plt.plot([0, 3], [15, 15])\n",
    "#plt.hlines(14, 0, 3, linewidths=2)\n",
    "f.savefig('images/heatmap_MDBImpact.png' , dpi=300)\n",
    "f.savefig('images/heatmap_MDBImpact.pdf' , dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_HCA(df, metric='euclidean', method='average'):\n",
    "    \"Performs Hierarchical Clustering Analysis of a data set with chosen linkage method and distance metric.\"\n",
    "    \n",
    "    distances = dist.pdist(df, metric=metric)\n",
    "    \n",
    "    # method is one of\n",
    "    # ward, average, centroid, single, complete, weighted, median\n",
    "    Z = hier.linkage(distances, method=method)\n",
    "\n",
    "    # Cophenetic Correlation Coefficient\n",
    "    # (see how the clustering - from hier.linkage - preserves the original distances)\n",
    "    coph = hier.cophenet(Z, distances)\n",
    "    # Baker's gamma\n",
    "    mr = ma.mergerank(Z)\n",
    "    bg = mr[mr!=0]\n",
    "\n",
    "    return {'Z': Z, 'distances': distances, 'coph': coph, 'merge_rank': mr, \"Baker's Gamma\": bg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCA_as = perform_HCA(df, metric='Euclidean', method='ward')\n",
    "HCA_bs = perform_HCA(datasets['YD']['MDBI'], metric='Euclidean', method='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative dendogram plots - Newer\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "def color_list_to_matrix_and_cmap(colors, ind, axis=0):\n",
    "        if any(issubclass(type(x), list) for x in colors):\n",
    "            all_colors = set(itertools.chain(*colors))\n",
    "            n = len(colors)\n",
    "            m = len(colors[0])\n",
    "        else:\n",
    "            all_colors = set(colors)\n",
    "            n = 1\n",
    "            m = len(colors)\n",
    "            colors = [colors]\n",
    "        color_to_value = dict((col, i) for i, col in enumerate(all_colors))\n",
    "\n",
    "        matrix = np.array([color_to_value[c]\n",
    "                           for color in colors for c in color])\n",
    "\n",
    "        matrix = matrix.reshape((n, m))\n",
    "        matrix = matrix[:, ind]\n",
    "        if axis == 0:\n",
    "            # row-side:\n",
    "            matrix = matrix.T\n",
    "\n",
    "        cmap = mpl.colors.ListedColormap(all_colors)\n",
    "        return matrix, cmap\n",
    "\n",
    "def plot_dendogram2(Z, leaf_names, label_colors, title='', ax=None, no_labels=False, labelsize=12, **kwargs):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    hier.dendrogram(Z, labels=leaf_names, leaf_font_size=10, above_threshold_color='0.2', orientation='left',\n",
    "                    ax=ax, **kwargs)\n",
    "    #Coloring labels\n",
    "    #ax.set_ylabel('Distance (AU)')\n",
    "    ax.set_xlabel('Distance (AU)')\n",
    "    ax.set_title(title, fontsize = 15)\n",
    "    \n",
    "    #ax.tick_params(axis='x', which='major', pad=12)\n",
    "    ax.tick_params(axis='y', which='major', labelsize=labelsize, pad=12)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    #xlbls = ax.get_xmajorticklabels()\n",
    "    xlbls = ax.get_ymajorticklabels()\n",
    "    rectimage = []\n",
    "    for lbl in xlbls:\n",
    "        col = label_colors[lbl.get_text()]\n",
    "        lbl.set_color(col)\n",
    "        #lbl.set_fontweight('bold')\n",
    "        if no_labels:\n",
    "            lbl.set_color('w')\n",
    "        rectimage.append(col)\n",
    "\n",
    "    cols, cmap = color_list_to_matrix_and_cmap(rectimage, range(len(rectimage)), axis=0)\n",
    "\n",
    "    axins = inset_axes(ax, width=\"5%\", height=\"100%\",\n",
    "                   bbox_to_anchor=(1, 0, 1, 1),\n",
    "                   bbox_transform=ax.transAxes, loc=3, borderpad=0)\n",
    "\n",
    "    axins.pcolor(cols, cmap=cmap, edgecolors='w', linewidths=1)\n",
    "    axins.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(5, 5))\n",
    "name = 'YD'\n",
    "title = f\"Data set {datasets[name]['name']}, MDBI after scaling\"\n",
    "plot_dendogram2(HCA_as['Z'], \n",
    "               datasets['YD']['target'], ax=ax,\n",
    "               label_colors=datasets['YD']['label_colors'], title=title,\n",
    "               color_threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transf.FeatureScaler(method='standard')\n",
    "df = tf.fit_transform(datasets['YD']['MDBI'].loc[:,list(MDBI_RF_Imp_Feat['YD']['Feature'])])\n",
    "\n",
    "MDB_2 = [f'PO$_3$H', 'CO$_2$', 'CO', 'O', 'CH$_2$', 'S', 'H$_2$', 'NH$_3$(âˆ’O)', 'CCH$_3$COOH', 'NCH', 'CONH', 'SO$_3$', \n",
    "         'CHCOOH', 'C$_2$H$_2$O', 'O(âˆ’NH)', 'H$_2$O', 'CHOH']\n",
    "#MDB_2 = MDBI_RF_Imp_Feat['YD'].loc[:,'Feature']\n",
    "\n",
    "row_cols = [datasets['YD']['label_colors'][lbl] for lbl in datasets['YD']['target']]\n",
    "\n",
    "g = sns.clustermap(df.T, yticklabels=MDB_2 ,cmap='PRGn', vmin=-3, vmax=3, col_linkage=HCA_as['Z'],  # method='ward',\n",
    "                    cbar_pos = (0.08, 0.1, 0.05, 0.5), col_colors=row_cols, linewidths=1.5,\n",
    "                   row_cluster=False)\n",
    "\n",
    "g.fig.set_size_inches((10,6))\n",
    "\n",
    "# some tweaks\n",
    "patches = []\n",
    "for lbl in datasets['YD']['classes']:\n",
    "    patches.append(mpatches.Patch(color=datasets['YD']['label_colors'][lbl], label=lbl))\n",
    "g.ax_heatmap.tick_params(axis='y', labelsize=15)\n",
    "g.ax_heatmap.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "\n",
    "leg = plt.legend(handles=patches, loc=3, bbox_to_anchor=(-0.75, 1.05, 0.5, 1),\n",
    "                     frameon=False, fontsize=14) \n",
    "    \n",
    "# Manually specify colorbar labelling after it's been generated\n",
    "colorbar = g.ax_heatmap.collections[0].colorbar\n",
    "colorbar.ax.tick_params(labelsize=14) \n",
    "\n",
    "g.savefig('images/clustermap_MDBImpact.png' , dpi=300)\n",
    "g.savefig('images/clustermap_MDBImpact.pdf' , dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transf.FeatureScaler(method='standard')\n",
    "df = tf.fit_transform(datasets['YD']['MDBI'].loc[:,list(MDBI_RF_Imp_Feat['YD']['Feature'])])\n",
    "\n",
    "MDB_2 = [f'PO$_3$H', 'CO$_2$', 'CO', 'O', 'CH$_2$', 'S', 'H$_2$', 'NH$_3$(âˆ’O)', 'CCH$_3$COOH', 'NCH', 'CONH', 'SO$_3$', \n",
    "         'CHCOOH', 'C$_2$H$_2$O', 'O(âˆ’NH)', 'H$_2$O', 'CHOH']\n",
    "#MDB_2 = MDBI_RF_Imp_Feat['YD'].loc[:,'Feature']\n",
    "\n",
    "row_cols = [datasets['YD']['label_colors'][lbl] for lbl in datasets['YD']['target']]\n",
    "\n",
    "g = sns.clustermap(df.T, yticklabels=MDB_2 ,cmap='PRGn', vmin=-3, vmax=3, col_linkage=HCA_as['Z'],  # method='ward',\n",
    "                    cbar_pos = (0.08, 0.1, 0.05, 0.5), col_colors=row_cols, linewidths=1.5,\n",
    "                   row_cluster=False)\n",
    "g.fig.suptitle('         MDBI', y=1.02, fontsize = 16) \n",
    "g.fig.set_size_inches((6,6))\n",
    "\n",
    "# some tweaks\n",
    "patches = []\n",
    "for lbl in datasets['YD']['classes']:\n",
    "    patches.append(mpatches.Patch(color=datasets['YD']['label_colors'][lbl], label=lbl))\n",
    "g.ax_heatmap.tick_params(axis='y', labelsize=13)\n",
    "g.ax_heatmap.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "\n",
    "# Manually specify colorbar labelling after it's been generated\n",
    "colorbar = g.ax_heatmap.collections[0].colorbar\n",
    "colorbar.ax.tick_params(labelsize=1) \n",
    "\n",
    "g.savefig('images/clustermap_MDBImpactFigpng' , dpi=300)\n",
    "g.savefig('images/clustermap_MDBImpactFig.pdf' , dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WMDBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sns.heatmap\n",
    "f, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "tf = transf.FeatureScaler(method='standard')\n",
    "df = tf.fit_transform(datasets['YD']['WMDBI'].loc[:,list(WMDBI_RF_Imp_Feat['YD']['Feature'])])\n",
    "\n",
    "MDB_2 = WMDBI_RF_Imp_Feat['YD'].loc[:,'Feature']\n",
    "\n",
    "g = sns.heatmap(df.T, xticklabels=False, yticklabels=MDB_2, cmap='PRGn', vmin=-3, vmax=3)\n",
    "g.set_yticklabels(g.get_ymajorticklabels(), fontsize = 14)\n",
    "\n",
    "# Manually specify colorbar labelling after it's been generated\n",
    "colorbar = g.collections[0].colorbar\n",
    "colorbar.ax.tick_params(labelsize=14) \n",
    "\n",
    "# thick line between the samples of different classes\n",
    "for i in range(3,15,3):\n",
    "    ax.axvline(i, color='white', lw=5)\n",
    "ax.tick_params(length=0)\n",
    "plt.text(1.5, 17.8, 'WT', ha='center', fontsize = 18, color = datasets['YD']['label_colors']['WT'])\n",
    "plt.text(4.5, 17.8, 'Î”GRE3', ha='center', fontsize = 18, color = datasets['YD']['label_colors']['Î”GRE3'])\n",
    "plt.text(7.5, 17.8, 'Î”ENO1', ha='center', fontsize = 18, color = datasets['YD']['label_colors']['Î”ENO1'])\n",
    "plt.text(10.5, 17.8, 'Î”GLO1', ha='center', fontsize = 18, color = datasets['YD']['label_colors']['Î”GLO1'])\n",
    "plt.text(13.5, 17.8, 'Î”GLO2', ha='center', fontsize = 18, color = datasets['YD']['label_colors']['Î”GLO2'])\n",
    "#plt.plot([0, 3], [15, 15])\n",
    "#plt.hlines(14, 0, 3, linewidths=2)\n",
    "f.savefig('images/heatmap_WMDBImpact.png' , dpi=300)\n",
    "f.savefig('images/heatmap_WMDBImpact.pdf' , dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCA_as = perform_HCA(df.replace({np.nan:0}), metric='Euclidean', method='ward')\n",
    "#HCA_bs = perform_HCA(datasets['YD']['WMDBI'], metric='Euclidean', method='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(5, 5))\n",
    "name = 'YD'\n",
    "title = f\"Data set {datasets[name]['name']}, WMDBI after scaling\"\n",
    "plot_dendogram2(HCA_as['Z'], \n",
    "               datasets['YD']['target'], ax=ax,\n",
    "               label_colors=datasets['YD']['label_colors'], title=title,\n",
    "               color_threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transf.FeatureScaler(method='standard')\n",
    "df = tf.fit_transform(datasets['YD']['MDBI'].loc[:,list(WMDBI_RF_Imp_Feat['YD']['Feature'])])\n",
    "\n",
    "MDB_2 = [f'PO$_3$H', 'NCH', 'H$_2$', 'CO', 'CCH$_3$COOH', 'CH$_2$', 'O', 'CONH', 'S', 'CHCOOH', 'NH$_3$(âˆ’O)', 'H$_2$O',\n",
    "         'CO$_2$', 'O(âˆ’NH)', 'C$_2$H$_2$O', 'SO$_3$', 'CHOH']\n",
    "#MDB_2 = WMDBI_RF_Imp_Feat['YD'].loc[:,'Feature']\n",
    "\n",
    "row_cols = [datasets['YD']['label_colors'][lbl] for lbl in datasets['YD']['target']]\n",
    "\n",
    "g = sns.clustermap(df.T, yticklabels=MDB_2 ,cmap='PRGn', vmin=-3, vmax=3, col_linkage=HCA_as['Z'],  # method='ward',\n",
    "                    cbar_pos = (0.08, 0.1, 0.05, 0.5), col_colors=row_cols, linewidths=1.5,\n",
    "                   row_cluster=False)\n",
    "\n",
    "g.fig.set_size_inches((10,6))\n",
    "\n",
    "# some tweaks\n",
    "patches = []\n",
    "for lbl in datasets['YD']['classes']:\n",
    "    patches.append(mpatches.Patch(color=datasets['YD']['label_colors'][lbl], label=lbl))\n",
    "g.ax_heatmap.tick_params(axis='y', labelsize=15)\n",
    "g.ax_heatmap.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "\n",
    "leg = plt.legend(handles=patches, loc=3, bbox_to_anchor=(-0.75, 1.05, 0.5, 1),\n",
    "                     frameon=False, fontsize=14)\n",
    "    \n",
    "# Manually specify colorbar labelling after it's been generated\n",
    "colorbar = g.ax_heatmap.collections[0].colorbar\n",
    "colorbar.ax.tick_params(labelsize=14) \n",
    "\n",
    "g.savefig('images/clustermap_WMDBImpact.png' , dpi=300)\n",
    "g.savefig('images/clustermap_WMDBImpact.pdf' , dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transf.FeatureScaler(method='standard')\n",
    "df = tf.fit_transform(datasets['YD']['MDBI'].loc[:,list(WMDBI_RF_Imp_Feat['YD']['Feature'])])\n",
    "\n",
    "MDB_2 = [f'PO$_3$H', 'NCH', 'H$_2$', 'CO', 'CCH$_3$COOH', 'CH$_2$', 'O', 'CONH', 'S', 'CHCOOH', 'NH$_3$(âˆ’O)', 'H$_2$O',\n",
    "         'CO$_2$', 'O(âˆ’NH)', 'C$_2$H$_2$O', 'SO$_3$', 'CHOH']\n",
    "#MDB_2 = WMDBI_RF_Imp_Feat['YD'].loc[:,'Feature']\n",
    "\n",
    "row_cols = [datasets['YD']['label_colors'][lbl] for lbl in datasets['YD']['target']]\n",
    "\n",
    "g = sns.clustermap(df.T, yticklabels=MDB_2 ,cmap='PRGn', vmin=-3, vmax=3, col_linkage=HCA_as['Z'],  # method='ward',\n",
    "                    cbar_pos = (0.08, 0.1, 0.05, 0.5), col_colors=row_cols, linewidths=1.5,\n",
    "                   row_cluster=False)\n",
    "g.fig.suptitle('        WMDBI', y=1.02, fontsize = 16) \n",
    "g.fig.set_size_inches((6,6))\n",
    "\n",
    "# some tweaks\n",
    "patches = []\n",
    "for lbl in datasets['YD']['classes']:\n",
    "    patches.append(mpatches.Patch(color=datasets['YD']['label_colors'][lbl], label=lbl))\n",
    "g.ax_heatmap.tick_params(axis='y', labelsize=13)\n",
    "g.ax_heatmap.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    \n",
    "# Manually specify colorbar labelling after it's been generated\n",
    "colorbar = g.ax_heatmap.collections[0].colorbar\n",
    "colorbar.ax.tick_params(labelsize=1)\n",
    "\n",
    "g.savefig('images/clustermap_WMDBImpactFig.png' , dpi=300)\n",
    "g.savefig('images/clustermap_WMDBImpactFig.pdf' , dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection in Latent Structures Discriminant Analysis (PLS-DA)\n",
    "\n",
    "PLS-DA models were built using the `PLSRegression` of scikit-learn.\n",
    "\n",
    "**Decision Rule**\n",
    "\n",
    "For the multi-class problem, class membership was encoded by the one-hot encoding method, and the prediction decision samples were assigned to the class corresponding to the maximum value in ypred of the PLS output. For two-class problems, class membership was encoded as 0 or 1, with 0.5 threshold for decision. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization - Search for the best number of components of PLS model\n",
    "\n",
    "The number of components were optimized by the 1 - PRESS/SS or Q$^2$ (PLS Score) of models built with 1 to n components.\n",
    "\n",
    "PRESS - Predictive Residual Sum of Squares; SS - residual Sum of Squares\n",
    "\n",
    "Strategy: Build PLS-DA with different number of components and extract the PLS score (inverse relation to the mean-squared error ) of the models estimated with stratified k-fold cross-validation. Observe at which point (number of components) the PLS Score starts approaching a \"stable maximum value\". This was done using the modified `optim_PLSDA_n_components` from multianalysis.py shown below.\n",
    "\n",
    "These regression metrics are not suitable to evaluate the performance of the classifier, they were just used to optimize the number of components to build the final PLS-DA models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = True #False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Altered version of optim_PLSDA_n_components taking into account the treated datasets in the 'iter_fold_splits' key.\n",
    "# Inside this dict, there are many nested dicts that culminate in the independently treated training and test dataset for\n",
    "# all iterations and fold splits (for k-fold cross-validation) as well as each tested data pre-treatment.\n",
    "def optim_PLSDA_n_components(datasets, encode2as1vector=True, scale=False, max_comp=50):\n",
    "    \n",
    "    ds_iter = datasets['iter_fold_splits']\n",
    "    \n",
    "    # Preparating lists to store results\n",
    "    CVs = []\n",
    "    CVr2s = []\n",
    "    MSEs = []\n",
    "    Accuracy = []\n",
    "\n",
    "    # Repeating for each component from 1 to max_comp\n",
    "    for i in range(1, max_comp + 1):\n",
    "        \n",
    "        # Setting up storing variables for n-fold cross-validation\n",
    "        cv = []\n",
    "        cvr2 = []\n",
    "        mse = []\n",
    "        accuracy = []\n",
    "        nright = 0\n",
    "        \n",
    "        # Fit and evaluate a Random Forest model for each fold in stratified k-fold cross validation\n",
    "        # For iteration 1\n",
    "        for fold in ds_iter[1]['train'].keys():\n",
    "            \n",
    "            # Set up the Y matrix for PLSRegression\n",
    "            train_group_len = len(ds_iter[1]['train'][fold]['target'])\n",
    "            labels = ds_iter[1]['train'][fold]['target'] + ds_iter[1]['test'][fold]['target']\n",
    "            unique_labels = list(pd.unique(labels))\n",
    "            is1vector = len(unique_labels) == 2 and encode2as1vector\n",
    "            matrix = ma._generate_y_PLSDA(labels, unique_labels, is1vector)\n",
    "            \n",
    "            # Divide the Y into the respective training and testing sets\n",
    "            if is1vector:\n",
    "                # keep a copy to use later\n",
    "                target1D = matrix.copy()\n",
    "                correct = target1D[train_group_len:]\n",
    "                y_train, y_test = matrix[:train_group_len], matrix[train_group_len:]\n",
    "            else:\n",
    "                y_train, y_test = matrix.iloc[:train_group_len], matrix.iloc[train_group_len:]\n",
    "                \n",
    "            # Fit PLS model\n",
    "            plsda = PLSRegression(n_components=i, scale=scale)\n",
    "            plsda.fit(X=ds_iter[1]['train'][fold][treatment], Y=y_train)\n",
    "\n",
    "            # Obtain results with the test group\n",
    "            y_pred = plsda.predict(ds_iter[1]['test'][fold][treatment])\n",
    "            cvr2.append(r2_score(y_test, y_pred))\n",
    "            \n",
    "            # Obtain results with the test group\n",
    "            y_pred = plsda.predict(ds_iter[1]['test'][fold][treatment])\n",
    "            cv.append(plsda.score(ds_iter[1]['test'][fold][treatment], y_test))\n",
    "            cvr2.append(r2_score(plsda.predict(ds_iter[1]['train'][fold][treatment]), y_train))\n",
    "            mse.append(mean_squared_error(y_test, y_pred))\n",
    "            \n",
    "            # Decision rule for classification\n",
    "            # Decision rule chosen: sample belongs to group where it has max y_pred (closer to 1)\n",
    "            # In case of 1,0 encoding for two groups, round to nearest integer to compare\n",
    "\n",
    "            if not is1vector:\n",
    "                for i in range(len(y_pred)):\n",
    "                    if list(y_test.iloc[i, :]).index(max(y_test.iloc[i, :])) == np.argmax(\n",
    "                        y_pred[i]\n",
    "                    ):\n",
    "                        nright += 1  # Correct prediction\n",
    "            else:\n",
    "                rounded = np.round(y_pred)\n",
    "                for i in range(len(y_pred)):\n",
    "                    if rounded[i] == correct[i]:\n",
    "                        nright += 1  # Correct prediction\n",
    "\n",
    "            # Calculate accuracy for this iteration\n",
    "            accuracy.append(nright / len(labels))\n",
    "\n",
    "        # Storing results for each number of components\n",
    "        CVs.append(np.mean(cv))\n",
    "        CVr2s.append(np.mean(cvr2))\n",
    "        MSEs.append(np.mean(mse))\n",
    "        Accuracy.append(np.mean(accuracy)) # not used yet...\n",
    "\n",
    "    return PLSDA_optim_results(CVscores=CVs, CVR2=CVr2s, MSE=MSEs)\n",
    "\n",
    "PLSDA_optim_results = namedtuple('PLSDA_optim_results', 'CVscores CVR2 MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "np.random.seed(16)\n",
    "GENERATE=True\n",
    "if GENERATE:\n",
    "    treatments = ('NGP', 'NGP_RF', 'Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11')\n",
    "    # above is to supress PLS warnings\n",
    "\n",
    "    # Store Results\n",
    "    PLS_optim = {}\n",
    "\n",
    "    # Build and extract metrics from models build with different number of components by using the optim_PLS function.\n",
    "    for name, dataset in datasets.items():\n",
    "        for treatment in treatments:\n",
    "            print(f'Fitting PLS-DA model for {name} with treatment {treatment}', end=' ...')\n",
    "            plsdaname = name + ' ' + treatment\n",
    "            PLS_optim[plsdaname] = {'dskey': name, 'dataset':dataset['name'], 'treatment':treatment}\n",
    "\n",
    "            if name.startswith('YD'):\n",
    "                max_comp = 10\n",
    "            elif treatment.endswith('MDBI'):\n",
    "                max_comp = 10\n",
    "            else:\n",
    "                max_comp = 15\n",
    "            \n",
    "            scale = True\n",
    "            if treatment in ('NGP', 'NGP_RF'):\n",
    "                scale = False\n",
    "            \n",
    "            optim = optim_PLSDA_n_components(dataset,\n",
    "                                            max_comp=max_comp, scale=scale).CVscores\n",
    "            \n",
    "            PLS_optim[plsdaname]['CV_scores'] = optim\n",
    "            print(f'done')\n",
    "\n",
    "    fname = 'store_files/PLSDA_optim.json'\n",
    "    with open(fname, \"w\", encoding='utf8') as write_file:\n",
    "        json.dump(PLS_optim, write_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read prior results\n",
    "fname = 'store_files/PLSDA_optim.json'\n",
    "with open(fname, \"r\", encoding='utf8') as read_file:\n",
    "    PLS_optim = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "        f, axs = plt.subplots(3, 2, figsize=(12,15), constrained_layout=True)\n",
    "        ranges = [range(i, i+8) for i in (0, 8, 16, 24, 32)]\n",
    "        titles = ['GDg2-', 'GDc2-', 'YD', 'GD types', 'HD']\n",
    "        col = treat_colors[-2:] + treat_colors[1:]\n",
    "        for irange, title, ax in zip(ranges, titles, axs.ravel()):   \n",
    "            for i in irange:\n",
    "                name = list(PLS_optim.keys())[i]\n",
    "                ax.plot(range(1, len(PLS_optim[name]['CV_scores']) + 1), PLS_optim[name]['CV_scores'], \n",
    "                         label=PLS_optim[name]['treatment'], color = col[i%8])\n",
    "            ax.set(xlabel='Number of Components',\n",
    "                    ylabel='PLS Score (1 - PRESS/SS)',\n",
    "                    title=title)\n",
    "            ax.legend(loc='lower left')\n",
    "            ax.set_ylim([0, 1])\n",
    "            \n",
    "        axs[2][1].remove()\n",
    "\n",
    "        #for letter, ax in zip('ABCDEFGH', axs.ravel()):\n",
    "        #    ax.text(0.88, 0.9, letter, ha='left', va='center', fontsize=15, weight='bold',\n",
    "        #        transform=ax.transAxes,\n",
    "        #        bbox=dict(facecolor='white', alpha=0.9))\n",
    "\n",
    "        #f.suptitle('Optimization of the number of trees')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the YD and GD types, PLS-DA models are going to be built with 6 components.\n",
    "\n",
    "For the other GD datasets, PLS-DA models are going to be built with 10 components.\n",
    "\n",
    "For the HD, PLS-DA models are going to be built with 10 components.\n",
    "\n",
    "For the MDBI and WMBI analysis of Sample MDiNs, PLS-DA models are going to be built with 4 and 6 components, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLS-DA models\n",
    "\n",
    "PLS-DA models were built with the `PLSRegression` (PLS2 algorithm used) from scikit-learn using the `PLSDA_model_CV` from multianalysis.py (each step explained better there).\n",
    "\n",
    "This function performs n iterations to randomly sample the folds in k-fold cross-validation - more combinations of training and test samples are used to offset the small (in terms of samples per group) dataset. \n",
    "\n",
    "It then stores predictive accuracy of the models, the Q$^2$ score (across the iterations) and an ordered list of the most to least important features (average across the iterations) in building the model according to a chosen feature importance metric.\n",
    "\n",
    "The function allows the choice of 3 different feature importance metrics (feat_type):\n",
    "\n",
    "- **VIP (Variable Importance/Influence in Projection)** - used in the paper\n",
    "- Coef. (regression coefficients - sum)\n",
    "- Weights (Sum of the X-weights for each feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLSDA_model_CV - PLSDA application and result extraction.\n",
    "# Altered version of PLSDA_model_CV taking into account the treated datasets in the 'iter_fold_splits' key of each dataset dict.\n",
    "# Inside this dict, there are many nested dicts that culminate in the independently treated training and test dataset for all\n",
    "# iterations and fold splits (for k-fold cross-validation) as well as each tested data pre-treatment.\n",
    "def PLSDA_model_CV(datasets, treatment, n_comp=10,\n",
    "                   encode2as1vector=True,\n",
    "                   scale=False,\n",
    "                   feat_type='Coef'):\n",
    "    \n",
    "    # Setting up lists and matrices to store results\n",
    "    CVR2 = []\n",
    "    accuracies = []\n",
    "    #Imp_Feat = np.zeros((iter_num * n_fold, df.shape[1]))\n",
    "    Imp_Feat = {}\n",
    "    ds_iter = datasets['iter_fold_splits']\n",
    "    f = 0\n",
    "        \n",
    "    # Number of times PLS-DA cross-validation is made\n",
    "    # with `n_fold` randomly generated folds.\n",
    "    for itr in range(len(ds_iter.keys())):\n",
    "\n",
    "        # Setting up storing variables for n-fold cross-validation\n",
    "        nright = 0\n",
    "        cvr2 = []\n",
    "        \n",
    "        # Fit and evaluate a PLS-DA model for each fold in stratified k-fold cross validation\n",
    "        for fold in ds_iter[itr+1]['train'].keys():\n",
    "            \n",
    "            # Set up the Y matrix for PLSRegression\n",
    "            train_group_len = len(ds_iter[itr+1]['train'][fold]['target'])\n",
    "            labels = ds_iter[itr+1]['train'][fold]['target'] + ds_iter[itr+1]['test'][fold]['target']\n",
    "            unique_labels = list(pd.unique(labels))\n",
    "            is1vector = len(unique_labels) == 2 and encode2as1vector\n",
    "            matrix = ma._generate_y_PLSDA(labels, unique_labels, is1vector)\n",
    "\n",
    "            # Divide the Y into the respective training and testing sets\n",
    "            if is1vector:\n",
    "                # keep a copy to use later\n",
    "                target1D = matrix.copy()\n",
    "                correct = target1D[train_group_len:]\n",
    "                y_train, y_test = matrix[:train_group_len], matrix[train_group_len:]\n",
    "            else:\n",
    "                y_train, y_test = matrix.iloc[:train_group_len], matrix.iloc[train_group_len:]\n",
    "                \n",
    "            #print(fold, itr+1)\n",
    "            # Fit PLS model\n",
    "            plsda = PLSRegression(n_components=n_comp, scale=scale)\n",
    "            plsda.fit(X=ds_iter[itr+1]['train'][fold][treatment], Y=y_train)\n",
    "\n",
    "            # Obtain results with the test group\n",
    "            y_pred = plsda.predict(ds_iter[itr+1]['test'][fold][treatment])\n",
    "            cvr2.append(r2_score(y_test, y_pred))\n",
    "\n",
    "            # Decision rule for classification\n",
    "            # Decision rule chosen: sample belongs to group where it has max y_pred (closer to 1)\n",
    "            # In case of 1,0 encoding for two groups, round to nearest integer to compare\n",
    "            # if not is1vector:\n",
    "            #     for i in range(len(y_pred)):\n",
    "            #         where_max = np.argmax(y_pred[i])\n",
    "\n",
    "            if not is1vector:\n",
    "                for i in range(len(y_pred)):\n",
    "                    if list(y_test.iloc[i, :]).index(max(y_test.iloc[i, :])) == np.argmax(\n",
    "                        y_pred[i]\n",
    "                    ):\n",
    "                        nright += 1  # Correct prediction\n",
    "            else:\n",
    "                rounded = np.round(y_pred)\n",
    "                for i in range(len(y_pred)):\n",
    "                    if rounded[i] == correct[i]:\n",
    "                        nright += 1  # Correct prediction\n",
    "\n",
    "            # Calculate important features (3 different methods to choose from)\n",
    "            if feat_type == 'VIP':\n",
    "                VIPS = ma._calculate_vips(plsda)\n",
    "                Imp_Feat[str(itr+1)+'-'+str(fold)] = dict(zip(ds_iter[itr+1]['train'][fold][treatment].columns,\n",
    "                                                      VIPS)) # Importance of each feature\n",
    "            elif feat_type == 'Coef':\n",
    "                Imp_Feat[str(itr+1)+'-'+str(fold)] = dict(zip(ds_iter[itr+1]['train'][fold][treatment].columns,\n",
    "                                                      abs(plsda.coef_).sum(axis=1))) # Importance of each feature\n",
    "            elif feat_type == 'Weights':\n",
    "                Imp_Feat[str(itr+1)+'-'+str(fold)] = dict(zip(ds_iter[itr+1]['train'][fold][treatment].columns,\n",
    "                                                      abs(plsda.x_weights_).sum(axis=1))) # Importance of each feature\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    'Type not Recognized. Types accepted: \"VIP\", \"Coef\", \"Weights\".'\n",
    "                )\n",
    "\n",
    "        # Calculate the accuracy of the group predicted and storing score results\n",
    "        accuracies.append(nright / len(labels))\n",
    "        CVR2.append(np.mean(cvr2))\n",
    "        \n",
    "    # Collect and order all important features values from each PLS-DA\n",
    "    Imp_Feat = pd.DataFrame.from_dict(Imp_Feat).replace({np.nan:0})\n",
    "    #print(len(Imp_Feat.columns))\n",
    "    Imp_Feat_sum = (Imp_Feat.sum(axis=1)/ (len(Imp_Feat.columns)))\n",
    "    sorted_Imp_Feat = Imp_Feat_sum.sort_values(ascending=False)\n",
    "    # Put them in a list of tuples shape to be able to be saved in json\n",
    "    Imp_Feat = []\n",
    "    for i in sorted_Imp_Feat.index:\n",
    "        Imp_Feat.append((i, sorted_Imp_Feat.loc[i]))\n",
    "\n",
    "    if len(ds_iter.keys()) == 1:\n",
    "        return {'accuracy': accuracies[0], 'Q2': CVR2[0], 'important_features': Imp_Feat}\n",
    "    else:\n",
    "        return {'accuracy': accuracies, 'Q2': CVR2, 'important_features': Imp_Feat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = True\n",
    "np.random.seed(16)\n",
    "if GENERATE:\n",
    "    PLSDA_all = {}\n",
    "\n",
    "    # For each differently-treated dataset, fit PLS-DA models on n randomly sampled folds (for stratified cross-validation)\n",
    "    for name, dataset in datasets.items():\n",
    "        \n",
    "        # Intensity-based pre-treatments\n",
    "        IDT_res = {}\n",
    "        for treatment in ('NGP', 'NGP_RF'):\n",
    "            print(f'Fitting a PLS-DA model to {name} with treatment {treatment}', end=' ...')\n",
    "            IDT_res[treatment] = {'dskey': name, 'dataset': dataset['name'], 'treatment':treatment}\n",
    "            if name.startswith('GD'):\n",
    "                n_comp = 10\n",
    "            elif name.startswith('HD'):\n",
    "                n_comp = 10\n",
    "            else:\n",
    "                n_comp = 6\n",
    "            \n",
    "            fit = PLSDA_model_CV(dataset, treatment,\n",
    "                                 scale=False,\n",
    "                                 n_comp=n_comp,\n",
    "                                 feat_type='VIP')\n",
    "\n",
    "            IDT_res[treatment].update(fit)\n",
    "\n",
    "            print(f'done')\n",
    "        \n",
    "        # Choose the Intensity-based Data pre-Treatment (IDT) with the highest accuracy\n",
    "        #print(np.mean(IDT_res['NGP_RF']['accuracy']), np.mean(IDT_res['NGP']['accuracy']))\n",
    "        if np.mean(IDT_res['NGP_RF']['accuracy']) >= np.mean(IDT_res['NGP']['accuracy']):\n",
    "            plsdaname = name + ' ' + 'IDT'\n",
    "            PLSDA_all[plsdaname] = IDT_res['NGP_RF']\n",
    "            PLSDA_all[plsdaname]['treatment'] = 'IDT'\n",
    "        else:\n",
    "            plsdaname = name + ' ' + 'IDT'\n",
    "            PLSDA_all[plsdaname] = IDT_res['NGP']\n",
    "            PLSDA_all[plsdaname]['treatment'] = 'IDT'\n",
    "\n",
    "        # Data matrices from the network analyses of sMDiNs\n",
    "        for treatment in ('Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11'):\n",
    "            print(f'Fitting a PLS-DA model to {name} with treatment {treatment}', end=' ...')\n",
    "            plsdaname = name + ' ' + treatment\n",
    "            PLSDA_all[plsdaname] = {'dskey': name, 'dataset': dataset['name'], 'treatment':treatment}\n",
    "            if name.startswith('GD'):\n",
    "                n_comp = 10\n",
    "            elif name.startswith('HD'):\n",
    "                n_comp = 10\n",
    "            else:\n",
    "                n_comp = 6\n",
    "            \n",
    "            if treatment == 'MDBI':\n",
    "                n_comp = 4\n",
    "            elif treatment == 'WMDBI':\n",
    "                n_comp = 6\n",
    "            \n",
    "            fit = PLSDA_model_CV(dataset, treatment,\n",
    "                                 scale=True,\n",
    "                                 n_comp=n_comp,\n",
    "                                 feat_type='VIP')\n",
    "            PLSDA_all[plsdaname].update(fit)\n",
    "            print(f'done')\n",
    "    \n",
    "    PLSDA_all\n",
    "    fname = 'store_files/PLSDA_all.json'\n",
    "    with open(fname, \"w\", encoding='utf8') as write_file:\n",
    "        json.dump(PLSDA_all, write_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results of the PLS-DA - Performance (Predictive Accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy across iterations\n",
    "# Read prior Results\n",
    "fname = 'store_files/PLSDA_all.json'\n",
    "with open(fname, \"r\", encoding='utf8') as read_file:\n",
    "    PLSDA_all = json.load(read_file)\n",
    "\n",
    "accuracies = pd.DataFrame({name: PLSDA_all[name]['accuracy'] for name in PLSDA_all})\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution for _GDg2-_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['IDT', 'Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11']\n",
    "\n",
    "# Violin plot of the distribution of the predictive accuracy (in %) across the iterations of randomly sampled folds for each \n",
    "# differently-treated dataset.\n",
    "\n",
    "cols2keep = [col for col in accuracies.columns if 'neg_global2' in col]\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    f, ax = plt.subplots(figsize=(14,6))\n",
    "    res100 = accuracies[cols2keep] * 100\n",
    "    res100.columns = column_names\n",
    "\n",
    "    #colors = ['blue','orange','green','red']\n",
    "    colors = treat_colors\n",
    "\n",
    "    sns.violinplot(data=res100, palette=colors)\n",
    "\n",
    "    plt.ylabel('Prediction Accuracy (%) - PLSDA', fontsize=13)\n",
    "    plt.ylim([25,100])\n",
    "    ax.tick_params(axis='x', which='major', labelsize = 18)\n",
    "    ax.tick_params(axis='y', which='major', labelsize = 15)\n",
    "    for ticklabel, tickcolor in zip(ax.get_xticklabels(), colors):\n",
    "        ticklabel.set_color(tickcolor)\n",
    "    f.suptitle('Predictive Accuracy of PLS-DA models - Grapevine Datasets global2', fontsize=16)\n",
    "    #plt.title('Yeast Dataset', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_stats = pd.DataFrame({'Average accuracy': accuracies.mean(axis=0),\n",
    "                               'STD': accuracies.std(axis=0)})\n",
    "accuracy_stats = accuracy_stats.assign(dataset=[PLSDA_all[name]['dataset'] for name in PLSDA_all],\n",
    "                                       treatment=[PLSDA_all[name]['treatment'] for name in PLSDA_all])\n",
    "accuracy_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Predictive Accuracies of PLS-DA models\n",
    "\n",
    "Error bars were built based on the standard deviation of the predictive accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4 = treat_colors\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.3):\n",
    "        f, ax = plt.subplots(1, 1, figsize=(16, 6))\n",
    "        x = np.arange(len(datasets))  # the label locations\n",
    "        labels = [datasets[name]['name'] for name in datasets]\n",
    "        width = 0.1  # the width of the bars\n",
    "        for i, treatment in enumerate(('IDT', 'Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11')):\n",
    "            acc_treatment = accuracy_stats[accuracy_stats['treatment']==treatment]\n",
    "            offset = - 0.25 + i * 0.1\n",
    "            rects = ax.bar(x + offset, acc_treatment['Average accuracy'], width, label=treatment, color = p4[i])\n",
    "            ax.errorbar(x + offset, y=acc_treatment['Average accuracy'], yerr=acc_treatment['STD'],\n",
    "                        ls='none', ecolor='0.2', capsize=3)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(labels)\n",
    "        ax.set(ylabel='Average accuracy', title='', ylim=(0.3,1.02))\n",
    "        #ax.text(-0.5, 0.95, 'B', weight='bold', fontsize=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy plots for RF and PLS-DA together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuraciesRF = pd.DataFrame({name: RF_all[name]['accuracy'] for name in RF_all})\n",
    "accuracy_stats_RF = pd.DataFrame({'Average accuracy': accuraciesRF.mean(axis=0),\n",
    "                                  'STD': accuraciesRF.std(axis=0)})\n",
    "accuracy_stats_RF = accuracy_stats_RF.assign(dataset=[RF_all[name]['dataset'] for name in RF_all],\n",
    "                                       treatment=[RF_all[name]['treatment'] for name in RF_all])\n",
    "\n",
    "\n",
    "accuraciesPLSDA = pd.DataFrame({name: PLSDA_all[name]['accuracy'] for name in PLSDA_all})\n",
    "accuracy_stats_PLSDA = pd.DataFrame({'Average accuracy': accuraciesPLSDA.mean(axis=0),\n",
    "                                     'STD': accuraciesPLSDA.std(axis=0)})\n",
    "accuracy_stats_PLSDA = accuracy_stats_PLSDA.assign(dataset=[PLSDA_all[name]['dataset'] for name in PLSDA_all],\n",
    "                                       treatment=[PLSDA_all[name]['treatment'] for name in PLSDA_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def endminus(x):\n",
    "    \"Replacing - with âˆ’ at the end of dataset names.\"\n",
    "    if x.endswith('-'):\n",
    "        return x.replace('-', 'âˆ’')\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4 = treat_colors\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.5):\n",
    "        f, (axu, axl) = plt.subplots(2, 1, figsize=(16, 10), constrained_layout=True)\n",
    "        x = np.arange(len(datasets))  # the label locations\n",
    "        labels = [endminus(datasets[name]['name']) for name in datasets]\n",
    "        width = 0.09  # the width of the bars\n",
    "        \n",
    "        for i, treatment in enumerate(('IDT', 'Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11')):\n",
    "            acc_treatment = accuracy_stats_RF[accuracy_stats_RF['treatment']==treatment]\n",
    "            offset = - 0.25 + i * 0.1\n",
    "            rects = axu.bar(x + offset, acc_treatment['Average accuracy'], width, label=treatment, color = p4[i])\n",
    "            axu.errorbar(x + offset, y=acc_treatment['Average accuracy'], yerr=acc_treatment['STD'],\n",
    "                        ls='none', ecolor='0.2', capsize=3)\n",
    "        axu.set_xticks(x)\n",
    "        axu.set_xticklabels(labels, fontsize=20)\n",
    "        axu.set(ylabel='Average accuracy', title='', ylim=(0.2,1.03))\n",
    "        axu.text(-0.5, 0.95, 'A', weight='bold', fontsize=16)\n",
    "        for spine in axu.spines.values():\n",
    "            spine.set_edgecolor('0.1')\n",
    "        \n",
    "        for i, treatment in enumerate(('IDT', 'Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11')):\n",
    "            acc_treatment = accuracy_stats_PLSDA[accuracy_stats_PLSDA['treatment']==treatment]\n",
    "            offset = - 0.25 + i * 0.1\n",
    "            rects = axl.bar(x + offset, acc_treatment['Average accuracy'], width, label=treatment, color = p4[i])\n",
    "            axl.errorbar(x + offset, y=acc_treatment['Average accuracy'], yerr=acc_treatment['STD'],\n",
    "                        ls='none', ecolor='0.2', capsize=3)\n",
    "        axl.set_xticks(x)\n",
    "        axl.set_xticklabels(labels, fontsize=20)\n",
    "        axl.set(ylabel='Average accuracy', title='', ylim=(0.2,1.03))\n",
    "        axl.text(-0.5, 0.95, 'B', weight='bold', fontsize=16)\n",
    "        for spine in axl.spines.values():\n",
    "            spine.set_edgecolor('0.1')\n",
    "        axu.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize=18)\n",
    "        plt.show()\n",
    "        #f.savefig('images/supervised_performance.pdf' , dpi=300)\n",
    "        #f.savefig('images/supervised_performance.jpg' , dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important feature analysis - PLS-DA\n",
    "\n",
    "**The same process as it was applied for Random Forest.**\n",
    "\n",
    "#### MDBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDBI_PLSDA_Imp_Feat = {}\n",
    "for dskey, ds in PLSDA_all.items():\n",
    "    if dskey.endswith(' MDBI'):\n",
    "        name, treat = dskey.split()\n",
    "        MDBI_PLSDA_Imp_Feat[name] = build_impfeat_table(ds['important_features'], colnames=['Feature', 'VIP Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDBI_PLSDA_Imp_Feat['YD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDBI_PLSDA_Imp_Feat['vitis_types']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WMDBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WMDBI_PLSDA_Imp_Feat = {}\n",
    "for dskey, ds in PLSDA_all.items():\n",
    "    if dskey.endswith('WMDBI'):\n",
    "        name, treat = dskey.split()\n",
    "        WMDBI_PLSDA_Imp_Feat[name] = build_impfeat_table(ds['important_features'], colnames=['Feature', 'VIP Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WMDBI_PLSDA_Imp_Feat['YD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WMDBI_PLSDA_Imp_Feat['vitis_types']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Sample Projection on the two most important Components/Latent Variables of PLS models built with the full dataset and sample representation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GDg2-, YD, GD types and HD after IDT (NGP or NGP_RF) or after Degree analysis of sMDiNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for projection\n",
    "def plot_PLS(principaldf, label_colors, components=(1,2), title=\"PLS\", ax=None):\n",
    "    \"Plot the projection of samples in the 2 main components of a PLS-DA model.\"\n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    loc_c1, loc_c2 = [c - 1 for c in components]\n",
    "    col_c1_name, col_c2_name = principaldf.columns[[loc_c1, loc_c2]]\n",
    "    \n",
    "    #ax.axis('equal')\n",
    "    ax.set_xlabel(f'{col_c1_name}')\n",
    "    ax.set_ylabel(f'{col_c2_name}')\n",
    "\n",
    "    unique_labels = principaldf['Label'].unique()\n",
    "\n",
    "    for lbl in unique_labels:\n",
    "        subset = principaldf[principaldf['Label']==lbl]\n",
    "        ax.scatter(subset[col_c1_name],\n",
    "                   subset[col_c2_name],\n",
    "                   s=50, color=label_colors[lbl], label=lbl)\n",
    "\n",
    "    #ax.legend(framealpha=1)\n",
    "    ax.set_title(title, fontsize=15)\n",
    "\n",
    "def plot_ellipses_PLS(principaldf, label_colors, components=(1,2),ax=None, q=None, nstd=2):\n",
    "    \"Plot the projection of samples in the 2 main components of a PLS-DA model.\"\n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    loc_c1, loc_c2 = [c - 1 for c in components]\n",
    "    points = principaldf.iloc[:, [loc_c1, loc_c2]]\n",
    "    \n",
    "    #ax.axis('equal')\n",
    "\n",
    "    unique_labels = principaldf['Label'].unique()\n",
    "\n",
    "    for lbl in unique_labels:\n",
    "        subset_points = points[principaldf['Label']==lbl]\n",
    "        plot_confidence_ellipse(subset_points, q, nstd, ax=ax, ec=label_colors[lbl], fc='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 11\n",
    "\n",
    "model, scores = ma.fit_PLSDA_model(datasets['GD_neg_class2']['NGP_RF'],\n",
    "                                   datasets['GD_neg_class2']['target'], n_comp=n_components, scale=False)\n",
    "model2, scores2 = ma.fit_PLSDA_model(datasets['GD_neg_class2']['Degree'],\n",
    "                                     datasets['GD_neg_class2']['target'], n_comp=n_components, scale=True)\n",
    "\n",
    "lcolors = datasets['GD_neg_class2']['label_colors']\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "        fig, (axl, axr) = plt.subplots(1,2, figsize=(14,7))\n",
    "        plot_PLS(scores, lcolors, title=\"Negative GD class2, Intensity-based treatment\", ax=axl)\n",
    "        #plt.legend(loc='upper left', ncol=2)\n",
    "\n",
    "        plot_PLS(scores2, lcolors, title=\"Negative GD class2, sMDiN (Degree) treatment\", ax=axr)\n",
    "        axr.set_ylabel('')\n",
    "        axr.legend(loc='upper right', ncol=2)               \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 11\n",
    "\n",
    "model, scores = ma.fit_PLSDA_model(datasets['YD']['NGP'],\n",
    "                                   datasets['YD']['target'], n_comp=n_components, scale=False)\n",
    "model2, scores2 = ma.fit_PLSDA_model(datasets['YD']['Degree'],\n",
    "                                     datasets['YD']['target'], n_comp=n_components, scale=True)\n",
    "\n",
    "lcolors = datasets['YD']['label_colors']\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "        fig, (axl, axr) = plt.subplots(1,2, figsize=(14,7))\n",
    "        plot_PLS(scores, lcolors, title=\"YD, Intensity-based treatment\", ax=axl)\n",
    "        #plt.legend(loc='upper left', ncol=2)\n",
    "\n",
    "        plot_PLS(scores2, lcolors, title=\"YD, sMDiN (Degree) treatment\", ax=axr)\n",
    "        axr.set_ylabel('')\n",
    "        axr.legend(loc='upper left', ncol=2)               \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 11\n",
    "\n",
    "model, scores = ma.fit_PLSDA_model(datasets['vitis_types']['NGP'],\n",
    "                                   datasets['vitis_types']['target'], n_comp=n_components, scale=False)\n",
    "model2, scores2 = ma.fit_PLSDA_model(datasets['vitis_types']['Degree'],\n",
    "                                     datasets['vitis_types']['target'], n_comp=n_components, scale=True)\n",
    "\n",
    "lcolors = datasets['vitis_types']['label_colors']\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "        fig, (axl, axr) = plt.subplots(1,2, figsize=(14,7))\n",
    "        plot_PLS(scores, lcolors, title=\"GD target is Vitis types, Intensity-based treatment\", ax=axl)\n",
    "        #plt.legend(loc='upper left', ncol=2)\n",
    "\n",
    "        plot_PLS(scores2, lcolors, title=\"GD target is Vitis types, sMDiN (Degree) treatment\", ax=axr)\n",
    "        axr.set_ylabel('')\n",
    "        axr.legend(loc='upper right', ncol=1)               \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 11\n",
    "\n",
    "model, scores = ma.fit_PLSDA_model(datasets['HD']['NGP_RF'],\n",
    "                                   datasets['HD']['target'], n_comp=n_components, scale=False)\n",
    "model2, scores2 = ma.fit_PLSDA_model(datasets['HD']['Degree'],\n",
    "                                     datasets['HD']['target'], n_comp=n_components, scale=True)\n",
    "\n",
    "lcolors = datasets['HD']['label_colors']\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "        fig, (axl, axr) = plt.subplots(1,2, figsize=(14,7))\n",
    "        plot_PLS(scores, lcolors, title=\"HD, Intensity-based treatment\", ax=axl)\n",
    "        #plt.legend(loc='upper left', ncol=2)\n",
    "\n",
    "        plot_PLS(scores2, lcolors, title=\"HD, sMDiN (Degree) treatment\", ax=axr)\n",
    "        axr.set_ylabel('')\n",
    "        axr.legend(loc='upper right', ncol=1)               \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of Supervised Analysis of the HD datasets using the external test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dictionaries in train and test for the 5 sMDiN analysis (not created before, since there was no\n",
    "# danger of data leakage, each network analysis is independent from network to network)\n",
    "name, ds = 'HD', datasets['HD']\n",
    "\n",
    "for treat in ('Degree', 'Betweenness', 'Closeness', 'MDBI', 'GCD11'):\n",
    "    ds['train'][treat] = ds[treat].loc[ds['train']['data'].index]\n",
    "    ds['test'][treat] = ds[treat].loc[ds['test']['data'].index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_model_HD(ds, treatment, n_trees=200):\n",
    "\n",
    "    nfeats = ds['data'].shape[1]\n",
    "\n",
    "    # Setting up variables for result storing\n",
    "    imp_feat = {}\n",
    "    accuracy_scores = []\n",
    "        \n",
    "    # Fit and evaluate a Random Forest model\n",
    "    rf = skensemble.RandomForestClassifier(n_estimators=n_trees)\n",
    "    rf.fit(ds['train'][treatment], ds['train']['target'])\n",
    "            \n",
    "    # Compute performance and important features\n",
    "    accuracy_score =  rf.score(ds['test'][treatment], \n",
    "                                ds['test']['target']) # Prediction Accuracy\n",
    "\n",
    "    imp_feat = dict(zip(ds['train'][treatment].columns,\n",
    "                            rf.feature_importances_)) # Importance of each feature\n",
    "\n",
    "    # Collect and order all important features values from each Random Forest\n",
    "    imp_feat = pd.Series(imp_feat).replace({np.nan:0})\n",
    "    sorted_imp_feat = imp_feat.sort_values(ascending=False)\n",
    "    imp_feat = []\n",
    "    for i in sorted_imp_feat.index:\n",
    "        imp_feat.append((i, sorted_imp_feat.loc[i]))\n",
    "\n",
    "    return {'accuracy': accuracy_score, 'important_features': imp_feat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(16)\n",
    "\n",
    "RF_HD_res = {}\n",
    "\n",
    "# Application of the Random Forests\n",
    "name, dataset = 'HD', datasets['HD']\n",
    "\n",
    "# Intensity-based pre-treatments\n",
    "IDT_res = {}\n",
    "for treatment in ('NGP', 'NGP_RF'):\n",
    "\n",
    "    IDT_res[treatment] = {'dskey': name, 'dataset': dataset['name'], 'treatment':treatment}\n",
    "\n",
    "    fit = RF_model_HD(dataset, treatment, n_trees=100)\n",
    "    IDT_res[treatment].update(fit)\n",
    "\n",
    "# Choose the Intensity-based Data pre-Treatment (IDT) with the highest accuracy\n",
    "if IDT_res['NGP_RF']['accuracy'] >= IDT_res['NGP']['accuracy']:\n",
    "    rfname = 'IDT'\n",
    "    RF_HD_res[rfname] = IDT_res['NGP_RF']\n",
    "    RF_HD_res[rfname]['treatment'] = 'IDT'\n",
    "else:\n",
    "    rfname = 'IDT'\n",
    "    RF_HD_res[rfname] = IDT_res['NGP']\n",
    "    RF_HD_res[rfname]['treatment'] = 'IDT'\n",
    "\n",
    "for treatment in ('Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11'):\n",
    "\n",
    "    rfname = treatment\n",
    "    RF_HD_res[rfname] = {'dskey': name, 'dataset': dataset['name'], 'treatment':treatment}\n",
    "\n",
    "    fit = RF_model_HD(dataset, treatment, n_trees=100)\n",
    "    RF_HD_res[rfname].update(fit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "accuracies_RF_HD = pd.Series({name: RF_HD_res[name]['accuracy'] for name in RF_HD_res})\n",
    "accuracies_RF_HD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4 = treat_colors\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.3):\n",
    "        f, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "        x = np.arange(1)  # the label locations\n",
    "        width = 0.1  # the width of the bars\n",
    "        for i, treatment in enumerate(('IDT', 'Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11')):\n",
    "            acc_treatment = accuracies_RF_HD[accuracies_RF_HD.index==treatment]\n",
    "            offset = - 0.25 + i * 0.1\n",
    "            rects = ax.bar(x + offset, acc_treatment, width, label=treatment, color = p4[i])\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(['HD'])\n",
    "        ax.set(ylabel='Average accuracy', title='', ylim=(0.3,1.03))\n",
    "        ax.legend(loc='upper left', bbox_to_anchor=(0.10, 1), ncol=2, fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PLS-DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PLSDA_model_HD(ds, treatment, n_comp=10,\n",
    "                   encode2as1vector=True,\n",
    "                   scale=False,\n",
    "                   feat_type='Coef'):\n",
    "      \n",
    "    nright = 0\n",
    "    \n",
    "    # Fit and evaluate a PLS-DA model \n",
    "    # Setting up the y matrix\n",
    "    train_group_len = len(ds['train']['target'])\n",
    "    labels = ds['train']['target'] + ds['test']['target']\n",
    "    unique_labels = list(pd.unique(labels))\n",
    "    is1vector = len(unique_labels) == 2 and encode2as1vector\n",
    "    matrix = ma._generate_y_PLSDA(labels, unique_labels, is1vector)\n",
    "\n",
    "    if is1vector:\n",
    "        # keep a copy to use later\n",
    "        target1D = matrix.copy()\n",
    "        correct = target1D[train_group_len:]\n",
    "        y_train, y_test = matrix[:train_group_len], matrix[train_group_len:]\n",
    "    else:\n",
    "        y_train, y_test = matrix.iloc[:train_group_len], matrix.iloc[train_group_len:]\n",
    "\n",
    "    # Fit PLS model\n",
    "    plsda = PLSRegression(n_components=n_comp, scale=scale)\n",
    "    plsda.fit(X=ds['train'][treatment], Y=y_train)\n",
    "\n",
    "    # Obtain results with the test group\n",
    "    y_pred = plsda.predict(ds['test'][treatment])\n",
    "    CVR2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Decision rule for classification\n",
    "    # Decision rule chosen: sample belongs to group where it has max y_pred (closer to 1)\n",
    "    # In case of 1,0 encoding for two groups, round to nearest integer to compare\n",
    "\n",
    "    if not is1vector:\n",
    "        for i in range(len(y_pred)):\n",
    "            if list(y_test.iloc[i, :]).index(max(y_test.iloc[i, :])) == np.argmax(\n",
    "                y_pred[i]\n",
    "            ):\n",
    "                nright += 1  # Correct prediction\n",
    "    else:\n",
    "        rounded = np.round(y_pred)\n",
    "        for i in range(len(y_pred)):\n",
    "            if rounded[i] == correct[i]:\n",
    "                nright += 1  # Correct prediction\n",
    "\n",
    "    # Calculate important features (3 different methods to choose from)\n",
    "    if feat_type == 'VIP':\n",
    "        VIPS = ma._calculate_vips(plsda)\n",
    "        Imp_Feat = dict(zip(ds['train'][treatment].columns, VIPS)) # Importance of each feature\n",
    "    elif feat_type == 'Coef':\n",
    "        Imp_Feat = dict(zip(ds['train'][treatment].columns, abs(plsda.coef_).sum(axis=1))) # Importance of each feature\n",
    "    elif feat_type == 'Weights':\n",
    "        Imp_Feat = dict(zip(ds['train'][treatment].columns, abs(plsda.x_weights_).sum(axis=1))) # Importance of each feature\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            'Type not Recognized. Types accepted: \"VIP\", \"Coef\", \"Weights\".'\n",
    "        )\n",
    "\n",
    "    # Calculate the accuracy of the group predicted\n",
    "    accuracies = nright / len(y_test) # Divided by len of test group\n",
    "        \n",
    "    # Collect and order important features values\n",
    "    Imp_Feat = pd.Series(Imp_Feat).replace({np.nan:0})\n",
    "    sorted_Imp_Feat = Imp_Feat.sort_values(ascending=False)\n",
    "    # Put them in a list of tuples shape to be able to be saved in json\n",
    "    Imp_Feat = []\n",
    "    for i in sorted_Imp_Feat.index:\n",
    "        Imp_Feat.append((i, sorted_Imp_Feat.loc[i]))\n",
    "\n",
    "    return {'accuracy': accuracies, 'Q2': CVR2, 'important_features': Imp_Feat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(16)\n",
    "\n",
    "PLSDA_HD_res = {}\n",
    "\n",
    "# Application of the PLS-DA\n",
    "name, dataset = 'HD', datasets['HD']\n",
    "\n",
    "# Intensity-based pre-treatments\n",
    "IDT_res = {}\n",
    "for treatment in ('NGP', 'NGP_RF'):\n",
    "\n",
    "    IDT_res[treatment] = {'dskey': name, 'dataset': dataset['name'], 'treatment':treatment}\n",
    "    n_comp = 10\n",
    "\n",
    "    fit = PLSDA_model_HD(dataset, treatment, scale=False, n_comp=n_comp)#, feat_type='VIP')\n",
    "    IDT_res[treatment].update(fit)\n",
    "\n",
    "# Choose the Intensity-based Data pre-Treatment (IDT) with the highest accuracy\n",
    "if IDT_res['NGP_RF']['accuracy'] >= IDT_res['NGP']['accuracy']:\n",
    "    plsdaname = 'IDT'\n",
    "    PLSDA_HD_res[plsdaname] = IDT_res['NGP_RF']\n",
    "    PLSDA_HD_res[plsdaname]['treatment'] = 'IDT'\n",
    "else:\n",
    "    plsdaname = 'IDT'\n",
    "    PLSDA_HD_res[plsdaname] = IDT_res['NGP']\n",
    "    PLSDA_HD_res[plsdaname]['treatment'] = 'IDT'\n",
    "\n",
    "\n",
    "# Data matrices from the network analyses of sMDiNs\n",
    "for treatment in ('Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11'):\n",
    "    \n",
    "    plsdaname = treatment\n",
    "    PLSDA_HD_res[plsdaname] = {'dskey': name, 'dataset': dataset['name'], 'treatment':treatment}\n",
    "    n_comp = 10\n",
    "\n",
    "    if treatment == 'MDBI':\n",
    "        n_comp = 4\n",
    "    elif treatment == 'WMDBI':\n",
    "        n_comp = 6\n",
    "\n",
    "    fit = PLSDA_model_HD(dataset, treatment, scale=True, n_comp=n_comp)\n",
    "    PLSDA_HD_res[plsdaname].update(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "accuracies_PLSDA_HD = pd.Series({name: PLSDA_HD_res[name]['accuracy'] for name in PLSDA_HD_res})\n",
    "accuracies_PLSDA_HD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4 = treat_colors\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.3):\n",
    "        f, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "        x = np.arange(1)  # the label locations\n",
    "        width = 0.1  # the width of the bars\n",
    "        for i, treatment in enumerate(('IDT', 'Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11')):\n",
    "            acc_treatment = accuracies_PLSDA_HD[accuracies_PLSDA_HD.index==treatment]\n",
    "            offset = - 0.25 + i * 0.1\n",
    "            rects = ax.bar(x + offset, acc_treatment, width, label=treatment, color = p4[i])\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(['HD'])\n",
    "        ax.set(ylabel='Average accuracy', title='', ylim=(0.3,1.03))\n",
    "        ax.legend(loc='upper left', bbox_to_anchor=(0.10, 1), ncol=2, fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure with everything  (cross-validation and HD external test set validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p4 = treat_colors\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.5):\n",
    "        fig=plt.figure(figsize=(16, 10))\n",
    "\n",
    "        gs=plt.GridSpec(2,7)\n",
    "\n",
    "        ax1=fig.add_subplot(gs[0,:6])\n",
    "        ax2=fig.add_subplot(gs[0,6])\n",
    "        ax3=fig.add_subplot(gs[1,:6]) \n",
    "        ax4=fig.add_subplot(gs[1,6]) \n",
    "\n",
    "        #f, (axu, axd) = plt.subplots(2, 2, figsize=(16, 10), constrained_layout=True)\n",
    "        x = np.arange(len(datasets))  # the label locations\n",
    "        labels = [endminus(datasets[name]['name']) for name in datasets]\n",
    "        width = 0.09  # the width of the bars\n",
    "        \n",
    "        for i, treatment in enumerate(('IDT', 'Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11')):\n",
    "            acc_treatment = accuracy_stats_RF[accuracy_stats_RF['treatment']==treatment]\n",
    "            offset = - 0.25 + i * 0.1\n",
    "            rects = ax1.bar(x + offset, acc_treatment['Average accuracy'], width, label=treatment, color = p4[i])\n",
    "            ax1.errorbar(x + offset, y=acc_treatment['Average accuracy'], yerr=acc_treatment['STD'],\n",
    "                        ls='none', ecolor='0.2', capsize=3)\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels(labels, fontsize=20)\n",
    "        ax1.set(ylabel='Average accuracy', title='', ylim=(0.2,1.03))\n",
    "        for spine in ax1.spines.values():\n",
    "            spine.set_edgecolor('0.1')\n",
    "        \n",
    "        for i, treatment in enumerate(('IDT', 'Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11')):\n",
    "            acc_treatment = accuracies_RF_HD[accuracies_RF_HD.index==treatment]\n",
    "            offset = - 0.25 + i * 0.1\n",
    "            rects = ax2.bar(0 + offset, acc_treatment, width, label=treatment, color = p4[i])\n",
    "\n",
    "        ax2.set_xticks([0])\n",
    "        ax2.set_xticklabels(['HD'], fontsize=20)\n",
    "        ax2.set(title='', ylim=(0.2,1.03))\n",
    "        ax2.set_yticklabels([])\n",
    "        for spine in ax2.spines.values():\n",
    "            spine.set_edgecolor('0.1')\n",
    "        \n",
    "        \n",
    "        for i, treatment in enumerate(('IDT', 'Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11')):\n",
    "            acc_treatment = accuracy_stats_PLSDA[accuracy_stats_PLSDA['treatment']==treatment]\n",
    "            offset = - 0.25 + i * 0.1\n",
    "            rects = ax3.bar(x + offset, acc_treatment['Average accuracy'], width, label=treatment, color = p4[i])\n",
    "            ax3.errorbar(x + offset, y=acc_treatment['Average accuracy'], yerr=acc_treatment['STD'],\n",
    "                        ls='none', ecolor='0.2', capsize=3)\n",
    "        ax3.set_xticks(x)\n",
    "        ax3.set_xticklabels(labels, fontsize=20)\n",
    "        ax3.set(ylabel='Average accuracy', title='', ylim=(0.2,1.03))\n",
    "        for spine in ax3.spines.values():\n",
    "            spine.set_edgecolor('0.1')\n",
    "        \n",
    "        for i, treatment in enumerate(('IDT', 'Degree', 'Betweenness', 'Closeness', 'MDBI', 'WMDBI', 'GCD11')):\n",
    "            acc_treatment = accuracies_PLSDA_HD[accuracies_PLSDA_HD.index==treatment]\n",
    "            offset = - 0.25 + i * 0.1\n",
    "            rects = ax4.bar(0 + offset, acc_treatment, width, label=treatment, color = p4[i])\n",
    "\n",
    "        ax4.set_xticks([0])\n",
    "        ax4.set_xticklabels(['HD'], fontsize=20)\n",
    "        ax4.set(title='', ylim=(0.2,1.03))\n",
    "        ax4.set_yticklabels([])\n",
    "        for spine in ax4.spines.values():\n",
    "            spine.set_edgecolor('0.1')\n",
    "        \n",
    "        ax2.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize=18)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        fig.savefig('images/supervised_performance_all.pdf' , dpi=300)\n",
    "        fig.savefig('images/supervised_performance_all.jpg' , dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure dir exists\n",
    "#path = Path.cwd() / \"store_files\"\n",
    "#path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#storepath = Path.cwd() / \"store_files\" / 'processed_data.h5'\n",
    "\n",
    "#store = pd.HDFStore(storepath, complevel=9, complib=\"blosc:blosclz\")\n",
    "#pd.set_option('io.hdf.default_format','table')\n",
    "\n",
    "# keep json serializable values and store dataFrames in HDF store\n",
    "\n",
    "#serializable = {}\n",
    "# Store in and h5 store the pandas dataframes created and in json file the rest\n",
    "# Since we have a lot of nested dicts in 'iter_fold_splits', the save and load the files back up code is a bit complex\n",
    "# Probably not the best way but functional\n",
    "# 'AA_' and 'TTS_' are used as special delimiters for the iter_fold_splits and train and test sets keys in the dict\n",
    "# Since they have the nested dicts to call on them when reading back the files\n",
    "#for dskey, dataset in datasets.items():\n",
    "#    serializable[dskey] = {}\n",
    "#    for key, value in dataset.items():\n",
    "        #print(dskey, key)\n",
    "#        if isinstance(value, pd.DataFrame):\n",
    "#            storekey = dskey + '_' + key\n",
    "            #print('-----', storekey)\n",
    "#            store[storekey] = value\n",
    "#            serializable[dskey][key] = f\"INSTORE_{storekey}\"\n",
    "#        elif key in ('MDiN', 'sMDiNs'):\n",
    "#            continue\n",
    "#        elif key == 'iter_fold_splits':\n",
    "#            for iteration, i in value.items():\n",
    "#                for group, n in i.items():\n",
    "#                    for fold, j in n.items():\n",
    "#                        #print(j)\n",
    "#                        for treat, dfs in j.items():\n",
    "#                            storekey = dskey + '_' + key + 'AA_' + str(iteration) + '_' + group + '_' + str(fold) + '_' + treat\n",
    "#                            if treat == 'target':\n",
    "#                                serializable[dskey][storekey] = dfs\n",
    "                            #print(df)\n",
    "#                            else:\n",
    "#                                store[storekey] = dfs\n",
    "#                                serializable[dskey][storekey] = f\"INSTORE_{storekey}\"\n",
    "#        elif key in ('train','test'):\n",
    "#            for treat, dfs in value.items():\n",
    "#                storekey = dskey + '_' + key + 'TTS_' + treat\n",
    "#                if treat == 'target':\n",
    "#                    serializable[dskey][storekey] = dfs\n",
    "                #print(df)\n",
    "#                else:\n",
    "#                    store[storekey] = dfs\n",
    "#                    serializable[dskey][storekey] = f\"INSTORE_{storekey}\"\n",
    "#        else:\n",
    "#            serializable[dskey][key] = value\n",
    "#store.close()\n",
    "\n",
    "\n",
    "#path = path / 'processed_data.json'\n",
    "#with open(path, \"w\", encoding='utf8') as write_file:\n",
    "#    json.dump(serializable, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
